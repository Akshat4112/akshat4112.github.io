[{"content":"","permalink":"https://akshat4112.github.io/events/cyber_valley_ai_bootcamp_stuttgart_tubingen_zurich_2023/","summary":"","title":"Cyber Valley AI Startup Bootcamp"},{"content":"Paper\nAuthors: Akshat Gupta, Laxman Singh Tomar, Ridhima Garg\nAbstract Cyber attacks deceive machines into believing something that does not exist in the first place. However, there are some to which even humans fall prey. One such famous attack that attackers have used over the years to exploit the vulnerability of vision is known to be a Homoglyph attack. It employs a primary yet effective mechanism to create illegitimate domains that are hard to differentiate from legit ones. Moreover, as the difference is pretty indistinguishable for a user to notice, they cannot stop themselves from clicking on these homoglyph domain names.\nIn our work, we created GlyphNet, an image dataset that contains 4M domains, both real and homoglyphs. Additionally, we introduce a baseline method for homoglyph attack detection system using an attention-based convolutional Neural Network. We show that our model can reach state-of-the-art accuracy in detecting homoglyph attacks with a 0.93 AUC on our dataset.\nIntroduction In cyber security, attackers employ different attacks to infiltrate our systems and networks, with the objective varying from stealing crucial information to inflicting system damage. One such deceptive attack is the homoglyph attack, which involves an attacker trying to fool humans and computer systems by using characters and symbols that may appear visually similar to characters used in real domain and process names but are different.\nDataset Proposed Dataset We have proposed a dataset consisting of real and homoglyph domains. We obtained domains from the Domains Project, comprising 500M domains, restricting our work to 2M domains due to hardware restrictions.\nHomoglyph Creation Algorithm We created a novel algorithm for the generation of homoglyph domains to ensure that real homoglyphs are generated with randomness and closeness. To achieve this, we sample homoglyph noise characters using Gaussian sampling from the glyph pool.\nImage Generation Homoglyph attacks exploit the weakness of human vision to differentiate real from homoglyph domain names. We rendered images from the real and homoglyph strings generated via our algorithm.\nMethodology Experimentation Dataset and Metrics We split our dataset into train, validation, and test, with a ratio of 70:20:10, respectively. We use accuracy, precision, recall, and F1 score as our evaluation metrics, along with the AUC score.\nExperimental Settings For training, we used binary cross-entropy as a Loss Function and RMSProp Optimizer. The network is trained for 30 epochs with early stopping, using a batch size of 256.\nResults We evaluated our model on two unpaired datasets for domain names, achieving an accuracy of 0.93 and an F1-score of 0.93, outperforming other models.\nReferences Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473. Boor, V.; Overmars, M. H.; and Van Der Stappen, A. F. 1999. The Gaussian sampling strategy for probabilistic roadmap planners. In Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C), volume 2, 1018–1023. IEEE. Cheng, L.; Liu, F.; and Yao, D. 2017. Enterprise data breach: causes, challenges, prevention, and future directions. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 7(5): e1211. Chollet, F.; et al. 2015. Keras. Damerau, F. J. 1964. A technique for computer detection and correction of spelling errors. Communications of the ACM, 7(3): 171–176. Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and FeiFei, L. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, 248–255. Ieee. Ginsberg, A.; and Yu, C. 2018. Rapid homoglyph prediction and detection. In 2018 1st International Conference on Data Intelligence and Security (ICDIS), 17–23. IEEE. Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y. 2014. Generative adversarial nets. Advances in neural information processing systems, 27. He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–778. Helms, M. M.; Ettkin, L. P.; and Morris, D. J. 2000. The risk of information compromise and approaches to prevention. The Journal of Strategic Information Systems, 9(1): 5–15. Hoffer, E.; and Ailon, N. 2015. Deep metric learning using triplet network. In International workshop on similarity-based pattern recognition, 84–92. Springer. Hong, J. 2012. The state of phishing attacks. Communications of the ACM, 55(1): 74–81. Isola, P.; Zhu, J.-Y.; Zhou, T.; and Efros, A. A. 2017. Imageto-image translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1125–1134. Citation @article{gupta2023glyphnet, title={GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks}, author={Gupta, Akshat and Tomar, Laxman Singh and Garg, Ridhima}, journal={arXiv preprint arXiv:2306.10392}, year={2023} } ","permalink":"https://akshat4112.github.io/publications/glyphnet/","summary":"\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2306.10392\"\u003ePaper\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAuthors:\u003c/strong\u003e Akshat Gupta, Laxman Singh Tomar, Ridhima Garg\u003c/p\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eCyber attacks deceive machines into believing something that does not exist in the first place. However, there are some to which even humans fall prey. One such famous attack that attackers have used over the years to exploit the vulnerability of vision is known to be a Homoglyph attack. It employs a primary yet effective mechanism to create illegitimate domains that are hard to differentiate from legit ones. Moreover, as the difference is pretty indistinguishable for a user to notice, they cannot stop themselves from clicking on these homoglyph domain names.\u003c/p\u003e","title":"GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks"},{"content":"","permalink":"https://akshat4112.github.io/events/mesh_hackathon_stuttgart_2023/","summary":"","title":"MESH Hackathon"},{"content":"Date of Event: September 6, 2019\nVenue: Dr. Akhilesh Das Gupta Institute of Technology \u0026amp; Management\nEvent Overview: In an exhilarating day filled with insights and hands-on activities, the Machine Learning workshop organized by Intel turned out to be a landmark event for aspiring ML enthusiasts. Our auditorium, buzzing with the energy of keen learners, became a crucible for innovation and deep understanding in the rapidly evolving field of Machine Learning.\nHighlights of the Session: Practical Learning Approach: The workshop kicked off by laying a solid foundation of Machine Learning concepts, employing a top-down teaching methodology. This approach, tailored to enhance student comprehension, was supplemented by easy-to-grasp visualizations, making complex theories accessible to all attendees.\nInteractive Sessions: A significant highlight was the interactive segment where students applied ML concepts in real-time. This \u0026rsquo;learning by doing\u0026rsquo; approach not only solidified their understanding but also sparked a curiosity to explore more.\nFocus on Modern AI Challenges: Beyond the basics, the workshop delved into the broader spectrum and future challenges of AI, presenting a realistic picture of the field today.\nHigh Engagement and Enthusiasm: The packed auditorium was a testament to the success of the workshop, with students showing a blend of contentment and eagerness to learn more.\nReflections: The day\u0026rsquo;s success was evident not just in the packed hall and the enthusiastic participation, but also in the heartwarming responses received on platforms like LinkedIn. This positive feedback has left us more energized and committed to organizing similar enriching events in the future.\nLooking Forward: The workshop has set a precedent for future sessions, highlighting the importance of practical, interactive learning in the field of Machine Learning and AI. We are excited about continuing this journey and contributing to the growth of aspiring Machine Learning professionals. Stay tuned for more updates and upcoming events in this space!\n","permalink":"https://akshat4112.github.io/talks/intel_machine_learning_workshop/","summary":"\u003cp\u003e\u003cstrong\u003eDate of Event:\u003c/strong\u003e September 6, 2019\u003cbr\u003e\n\u003cstrong\u003eVenue:\u003c/strong\u003e Dr. Akhilesh Das Gupta Institute of Technology \u0026amp; Management\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"event-overview\"\u003eEvent Overview:\u003c/h3\u003e\n\u003cp\u003eIn an exhilarating day filled with insights and hands-on activities, the Machine Learning workshop organized by Intel turned out to be a landmark event for aspiring ML enthusiasts. Our auditorium, buzzing with the energy of keen learners, became a crucible for innovation and deep understanding in the rapidly evolving field of Machine Learning.\u003c/p\u003e","title":"Recap of Intel's Machine Learning Workshop at Dr. Akhilesh Das Gupta Institute"},{"content":"","permalink":"https://akshat4112.github.io/publications/deep_learning_with_tensorflow/","summary":"","title":"Hands-on Deep Learning with Tensorflow 2.0"},{"content":"Date of Event: May 05, 2020\nVenue: Online\nEvent Overview: In May 2020, Poornima University in Rajasthan hosted a groundbreaking workshop focusing on the Role of Natural Language Processing (NLP) in Healthcare. This event provided a unique platform for healthcare professionals, technologists, and students to explore the intersection of advanced linguistic technology and healthcare applications.\nHighlights of the Workshop: Introduction to NLP in Healthcare: The workshop started with an overview of NLP and its evolving role in the healthcare sector, emphasizing how it transforms patient care and medical data analysis.\nHands-On Sessions: Participants engaged in hands-on training, where they learned to apply NLP tools in various healthcare scenarios, such as patient data interpretation, medical record analysis, and more.\nExpert-Led Discussions: Leading experts in NLP and healthcare IT shared their insights on the latest trends, challenges, and advancements in the field, fostering a deeper understanding among attendees.\nCase Studies and Applications: The event featured several case studies demonstrating successful NLP applications in healthcare, highlighting its potential in improving diagnosis, treatment, and patient engagement.\nEthical Considerations: A key part of the workshop was dedicated to discussing the ethical implications of using NLP in healthcare, including data privacy and the importance of unbiased algorithms.\nParticipant Engagement: The workshop saw active participation from attendees, who were keen to understand how NLP can revolutionize healthcare delivery. The interactive format allowed for an exchange of ideas and stimulated discussions on future innovations in this space.\nConclusion: The workshop on the Role of NLP in Healthcare at Poornima University marked an important step towards bridging the gap between technology and healthcare. It opened new avenues for innovation and collaboration, setting the stage for future breakthroughs that can significantly enhance the quality and efficiency of healthcare services.\n","permalink":"https://akshat4112.github.io/talks/nlp_in_healthcare/","summary":"\u003cp\u003e\u003cstrong\u003eDate of Event:\u003c/strong\u003e May 05, 2020\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eVenue:\u003c/strong\u003e Online\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"event-overview\"\u003eEvent Overview:\u003c/h3\u003e\n\u003cp\u003eIn May 2020, Poornima University in Rajasthan hosted a groundbreaking workshop focusing on the Role of Natural Language Processing (NLP) in Healthcare. This event provided a unique platform for healthcare professionals, technologists, and students to explore the intersection of advanced linguistic technology and healthcare applications.\u003c/p\u003e\n\u003ch3 id=\"highlights-of-the-workshop\"\u003eHighlights of the Workshop:\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eIntroduction to NLP in Healthcare:\u003c/strong\u003e The workshop started with an overview of NLP and its evolving role in the healthcare sector, emphasizing how it transforms patient care and medical data analysis.\u003c/p\u003e","title":"Role of Natural Language Processing in Healthcare"},{"content":"","permalink":"https://akshat4112.github.io/events/smart_india_hackathon_2017/","summary":"","title":"Smart India Hackathon 2017: Minitry of Earth Sciences"},{"content":"Generative modeling is currently one of the most thrilling domains in deep learning research. Traditional models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) have already demonstrated impressive capabilities in synthetically generating realistic data, such as images and text. However, diffusion models is swiftly gaining prominence as a powerful model in the arena of high-quality and stable generative modeling. This blog explores diffusion models, examining their operational mechanisms, architectural designs, training processes, sampling methods, and the key advantages that position them at the forefront of generative AI.\nThe foundations of diffusion models were introduced in papers by Sohl-Dickstein et al. and Ho et al.\nHow Do Diffusion Models Work? Diffusion models function on a principal strategy of training a model to reverse a gradual process of data corruption, transitioning from a clean data point to pure noise and then back to clean data point.\nImage Source: Ho et al.\nForward Diffusion Process This corruption is executed through the forward diffusion process. It is characterized by the iterative addition of small quantities of Gaussian noise to the data \\(x_0\\) over \\(T\\) discrete time steps. This process is mathematically expressed as:\n\\[ x_t = \\sqrt{1 - \\beta_t} \\times x_{t-1} + \\sqrt{\\beta_t} \\times \\epsilon \\]\nIn this equation, \\(x_t\\) represents the partially corrupted data at time \\(t\\), \\(\\beta_t\\) is the noise parameter that controls variance, and \\(\\epsilon\\) signifies Gaussian noise. As \\(t\\) increases, \\(\\beta_t\\) is progressively annealed from a lower to higher value, methodically erasing the structure in \\(x_0\\) until it becomes unrecognizable noise \\(x_T\\).\nReverse Diffusion Process The core of the diffusion model is a neural network trained to precisely reverse this forward process. It accepts \\(x_t\\) as input and predicts \\(x_{t-1}\\), the less noisy version from the preceding step. By consecutively predicting each step in reverse, the model systematically denoises \\(x_T\\) back into a clear sample \\(x_0\\).\nA critical aspect of this training involves denoising score matching, where the model aims to predict the gradient of the log-probability of \\(x_{t-1}\\) given \\(x_t\\). This approach, relying on noise data from the forward process, is key to the model\u0026rsquo;s stable training.\nDiffusion Model Architectures Diffusion models commonly utilize convolutional neural networks, particularly U-Net architectures. The contracting and expanding paths in U-Nets facilitate both local and global attention to the noise, yielding high-quality outputs.\nConditional variants of these models integrate class embeddings at intermediate layers, allowing for controlled sampling of specific classes of data, like images of diverse objects.\nTraining Process Diffusion models are distinct in that they are trained using a denoising score matching loss rather than a standard likelihood loss. During training, the model is exposed only to artificially noised data from the forward process, never to clean data. This approach enables large-scale stable training and mitigates issues like mode collapse, common in likelihood-based models such as GANs, especially on diverse datasets. The iterative training on noise data endows diffusion models with robust generative capabilities.\nSampling Methods To generate samples from a trained diffusion model, one starts with pure noise \\(x_T\\) and progressively predicts \\(x_{T-1}\\), \\(x_{T-2}\\), and so on, using the model\u0026rsquo;s predicted denoising score at each step.\nThe number of sampling steps is crucial; approximately 1000 steps can recover fine details clearly, whereas fewer steps might result in distorted outputs. Post-processing techniques, such as upscaling, can further enhance the quality of the samples.\nAdvantages Over Other Models Diffusion models offer several advantages over existing generative models, making them a promising new direction in the field:\nSample Quality: The iterative denoising process facilitates the creation of high-resolution, clear samples that effectively capture the complexity of data. Training Stability: Exposure to only artificial noise data prevents collapse issues and enables scalable training. Flexible Control: Class-conditional variants offer significant control over sampling specific data types. Parallelizable Sampling: Each step in the sampling process can be efficiently parallelized across GPUs. Current Limitations Despite their advantages, diffusion models do face certain limitations:\nSampling is computationally intensive, requiring hundreds of passes. Numerous hyperparameters related to the noise schedule needs careful tuning. Class-conditional guidance is limited compared to the desired level of control. The Future of Generative AI Diffusion models are exceptionally promising as generative models due to both sample quality and training stability. With rapid innovations in architecture, hyperparameters, and sampling techniques, they represent the new frontier in generative modeling with vast potentials still to be unlocked. As research continues, we can expect diffusion models to become even more powerful and flexible generative tools.\n","permalink":"https://akshat4112.github.io/posts/what_are_diffusion_models/","summary":"\u003cp\u003e\u003cstrong\u003eGenerative modeling\u003c/strong\u003e is currently one of the most thrilling domains in deep learning research.\nTraditional models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) have already demonstrated impressive capabilities in synthetically generating realistic data, such as images and text. However, \u003cstrong\u003ediffusion models\u003c/strong\u003e is swiftly gaining prominence as a powerful model in the arena of high-quality and stable generative modeling. This blog explores diffusion models, examining their operational mechanisms, architectural designs, training processes, sampling methods, and the key advantages that position them at the forefront of generative AI.\u003c/p\u003e","title":"What are Diffusion Models?"},{"content":" As machine learning systems are increasingly used in critical areas like finance, employment, and criminal justice, it\u0026rsquo;s essential to ensure these models are fair and do not discriminate against certain groups. In this post, I will explore the concept of fairness in machine learning.\nDefining Fairness Fairness in machine learning can be understood in several ways:\nGroup Fairness: This implies equal treatment or outcomes for different groups categorized by sensitive attributes like race or gender. For instance, ensuring a loan application system doesn\u0026rsquo;t have a higher false rejection rate for one gender compared to another.\nIndividual Fairness: This means that similar individuals should receive similar predictions or decisions, irrespective of their group membership. Two individuals with comparable financial backgrounds should get similar credit scores, regardless of their ethnicity or gender.\nCausal Fairness: Defined using causal modeling, it ensures similar predictions for individuals who would exhibit similar outcomes under different treatments. For example, a person\u0026rsquo;s chances of getting a job should not be influenced by their gender.\nSources of Unfairness Unfairness in machine learning models can arise from several factors:\nBiased Training Data: If the training data reflects historical human biases, the model will likely inherit these biases. Using Protected Variables: Direct use of attributes like race or gender in models can lead to disparate treatment. Proxy Variables: Models may learn to discriminate using variables correlated with protected attributes, like zip codes. Skewed Test Performance: Poor model performance on minority groups due to imbalanced datasets. Incorrect Similarity Metrics: Discriminatory definitions of similarity between individuals can introduce bias. Techniques to Improve Fairness Addressing unfairness involves strategies across the ML pipeline:\nPre-processing: Removing biases in training data and identifying proxy variables. In-processing: Modifying the model training process to incorporate fairness constraints. Post-processing: Applying techniques post-training to correct biases. Improved Evaluation: Using specific metrics to assess fairness in different contexts. Causal Modeling: Employing causal inference techniques to understand and mitigate biases. Real-World Example: Bias in Digital Recruitment Advertising A notable instance highlighting the need for fairness in AI was observed in digital recruitment advertising. An algorithm disproportionately showed high-salary job ads to men over women, influenced by biased historical data that reflected existing employment trends. This case underscores the importance of evaluating training data for biases and the necessity for ongoing algorithmic assessment to avoid reinforcing social inequalities.\nConclusion Achieving fairness in machine learning is a complex yet vital endeavor, requiring collaboration across various fields. With careful consideration and appropriate techniques, we can develop AI systems that are both ethical and equitable.\n","permalink":"https://akshat4112.github.io/posts/fairness_in_machine_learning_/","summary":"\u003chr\u003e\n\u003cp\u003eAs machine learning systems are increasingly used in critical areas like finance, employment, and criminal justice, it\u0026rsquo;s essential to ensure these models are fair and do not discriminate against certain groups. In this post, I will explore the concept of fairness in machine learning.\u003c/p\u003e\n\u003ch2 id=\"defining-fairness\"\u003eDefining Fairness\u003c/h2\u003e\n\u003cp\u003eFairness in machine learning can be understood in several ways:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eGroup Fairness\u003c/strong\u003e: This implies equal treatment or outcomes for different groups categorized by sensitive attributes like race or gender. For instance, ensuring a loan application system doesn\u0026rsquo;t have a higher false rejection rate for one gender compared to another.\u003c/p\u003e","title":"Fairness in Machine Learning"},{"content":"Date of Event: December 17, 2019\nVenue: Ujjain\nEvent Overview: Ujjain witnessed an enriching educational event in December 2019, with a workshop dedicated to introducing the fundamentals of Artificial Intelligence (AI). Designed for beginners and enthusiasts alike, this event served as a primer to the world of AI, attracting a diverse audience from students to professionals keen on understanding this cutting-edge technology.\nHighlights of the Workshop: Fundamentals of AI: The workshop focused on the core principles of AI, providing a comprehensive introduction to its basic concepts and terminologies.\nInteractive Learning Approach: To ensure a solid grasp of AI fundamentals, the workshop included interactive sessions and practical demonstrations, making complex topics accessible to all attendees.\nExpert Speakers: Knowledgeable speakers from the field of AI shared insights and real-world applications, offering a well-rounded perspective on the impact of AI in various industries.\nCollaborative Activities: Attendees participated in group activities designed to stimulate creative thinking and problem-solving in AI contexts.\nResource Sharing: The workshop also provided resources for further learning, encouraging participants to continue their AI education beyond the event.\nParticipant Experiences: The workshop was met with enthusiasm and curiosity, as attendees expressed their appreciation for the clear and engaging presentation of AI basics. Many participants noted how the workshop demystified AI and sparked their interest in exploring the field further.\nLooking Ahead: This introductory AI workshop has set the stage for more advanced discussions and learning opportunities in Ujjain. The positive response has paved the way for future events that will delve deeper into AI technologies and their applications.\nConclusion: The \u0026lsquo;Introduction to Artificial Intelligence\u0026rsquo; workshop in Ujjain was a significant step towards fostering a knowledgeable and skilled community ready to embrace AI advancements. As AI continues to evolve, Ujjain\u0026rsquo;s tech community is well-placed to be part of this transformative journey, equipped with the foundational knowledge imparted by this successful event.\n","permalink":"https://akshat4112.github.io/talks/kips_artificial_intelligence_workshop/","summary":"\u003cp\u003e\u003cstrong\u003eDate of Event:\u003c/strong\u003e December 17, 2019\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eVenue:\u003c/strong\u003e Ujjain\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"event-overview\"\u003eEvent Overview:\u003c/h3\u003e\n\u003cp\u003eUjjain witnessed an enriching educational event in December 2019, with a workshop dedicated to introducing the fundamentals of Artificial Intelligence (AI). Designed for beginners and enthusiasts alike, this event served as a primer to the world of AI, attracting a diverse audience from students to professionals keen on understanding this cutting-edge technology.\u003c/p\u003e\n\u003ch3 id=\"highlights-of-the-workshop\"\u003eHighlights of the Workshop:\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eFundamentals of AI:\u003c/strong\u003e The workshop focused on the core principles of AI, providing a comprehensive introduction to its basic concepts and terminologies.\u003c/p\u003e","title":"Introduction to Artificial Intelligence Workshop in Ujjain"},{"content":"If you\u0026rsquo;ve been working with modern AI systems — particularly in the realm of Large Language Models (LLMs), image embeddings, or recommendation engines — you\u0026rsquo;ve probably heard of vector databases. But what are they really? And why is everyone in the ML community suddenly so excited about them?\nLet me break it down in simple terms, along with how I’ve been exploring them in my own projects.\n🔍 The Problem: Why Traditional Databases Fall Short Traditional databases (like PostgreSQL or MongoDB) are great when you’re dealing with exact matches or relational queries:\n“Find all users from Stuttgart” “Show me orders placed in the last 30 days” But AI doesn\u0026rsquo;t speak in exact matches. For example:\n\u0026ldquo;Images similar to a cat\u0026rdquo; \u0026ldquo;Documents related to GDPR compliance\u0026rdquo; \u0026ldquo;People with similar resume embeddings\u0026rdquo; These are all semantic queries — and you need a system that understands similarity, not just exact matches. That’s where vector databases come in.\n🧭 What Is a Vector Database? A vector database is a specialized type of database designed to store and retrieve high-dimensional vectors — the kind you get from neural network embeddings.\nFor instance:\nAn image processed by a CNN might become a 512-dimensional vector. A sentence embedding from BERT might be a 768-dimensional vector. A product recommendation engine might embed user behavior in 128 dimensions. These aren’t human-readable, but they carry meaning in a latent space. A vector database allows you to store, index, and search those vectors efficiently.\n⚙️ How Do They Work? Here’s a simplified flow:\nGenerate Embeddings: Use a model like OpenAI’s embedding API, Hugging Face Transformers, or CLIP to convert your input (text/image/etc.) into a vector. Store the Vector: Save this vector along with metadata (e.g. document ID, title, tags) in the vector DB. Perform Similarity Search: When querying, your input is also converted into a vector, and the DB finds the closest vectors using metrics like cosine similarity or Euclidean distance. This is called Approximate Nearest Neighbor (ANN) search — the core engine behind vector DBs.\n📦 Popular Vector Databases Here are a few tools I’ve worked with or explored:\nPinecone: Fully managed and cloud-native, great for production LLM workflows. Weaviate: Open-source with hybrid search (keyword + vector). FAISS (Facebook AI Similarity Search): A C++/Python library for fast similarity search. Milvus: Industrial-grade open-source vector DB built for scale. Qdrant: Rust-based, developer-friendly, with REST and gRPC APIs. Chroma: Lightweight and ideal for quick local experiments or prototyping. 🚀 Real-World Use Cases Some practical examples I’ve seen or built:\nRAG (Retrieval-Augmented Generation) pipelines: Retrieving the most relevant documents before feeding them to an LLM. Image Search: Finding visually similar images using CLIP embeddings. Voiceprint Matching: In a speaker diarization project, I embedded speaker audio and searched for similar embeddings. Semantic QA: Matching a question against a corpus of answers using dense embeddings instead of keywords. 🧪 My Learnings \u0026amp; Tips Start Small: Use FAISS or Chroma locally before scaling to managed solutions like Pinecone. Hybrid Search Rocks: Combining vector similarity with keyword search (like in Weaviate or Elasticsearch) often yields better results. Fine-Tune Embeddings: Pretrained models work well, but fine-tuning with libraries like SentenceTransformers can significantly improve relevance. Storage + Speed Tradeoffs: ANN methods sacrifice some accuracy for speed — you’ll need to balance these based on your use case. 🧩 Final Thoughts Vector databases are not just a hype — they’re a foundational layer in any serious GenAI system. From semantic search to recommendation and RAG, they enable the kind of \u0026ldquo;intelligent recall\u0026rdquo; that was previously hard to build at scale.\nIf you’re building anything involving embeddings, I strongly recommend giving one of these tools a try. Feel free to reach out if you’re stuck or want to nerd out about vector indexing strategies 😄\nThanks for reading! I’ll be posting more about building scalable GenAI pipelines and multimodal systems — stay tuned.\n— Akshat\n","permalink":"https://akshat4112.github.io/posts/vector-databases/","summary":"An in-depth, beginner-friendly guide to vector databases, what they are, how they work, and where they fit in GenAI systems.","title":"What Are Vector Databases?"},{"content":"I\u0026rsquo;m a machine learning engineer and my research interests are in generative modelling, speech processing, text analysis, machine learning, and deep learning. Currently pursuing a master\u0026rsquo;s from the University of Stuttgart, my major is in computational linguistics.\nCurrent work Research work includes denoising diffusion on speaker embeddings, explainability of CRF-LSTM-based NER models, temporal and spatial word embeddings, and homoglyph detection using attention-based CNNs.\nMy work includes Before this, I worked at Quantiphi, Scanta, and Mobile Programming LLC as a machine learning engineer and worked on speaker diarization, multimodal sentiment analysis, NLP augmentor, clinical ner, chatbot using AWS Lex and Dialogflow, customer care call analytics, neural machine translation.\nBackground and history Previously I was an undergrad at APJ Abdul Kalam Technical University studying computers and maths. my major project was on \u0026ldquo;Automatic Catalogue Tagging using Deep Learning\u0026rdquo;. Other minor projects include an online examination system, school ERP, seawater quality monitoring system, and, online certificate generator. I\u0026rsquo;m from Agra and currently living in Stuttgart.\nOther Works Intel Software Innovator AAAI Reviewer Member of the Board of Studies at OP Jindal University Author with Packt publications Kaggle 3x expert, Top 1% of 300k+ Kaggle users Interests Table Tennis, Chess, Financial Markets, Quantum Physics ","permalink":"https://akshat4112.github.io/about/","summary":"\u003cp\u003eI\u0026rsquo;m a machine learning engineer and my research interests are in generative modelling, speech processing, text analysis, machine learning, and deep learning. Currently pursuing a master\u0026rsquo;s from the University of Stuttgart, my major is in computational linguistics.\u003c/p\u003e\n\u003ch2 id=\"current-work\"\u003eCurrent work\u003c/h2\u003e\n\u003cp\u003eResearch work includes denoising diffusion on speaker embeddings, explainability of CRF-LSTM-based NER models, temporal and spatial word embeddings, and homoglyph detection using attention-based CNNs.\u003c/p\u003e\n\u003ch2 id=\"my-work-includes\"\u003eMy work includes\u003c/h2\u003e\n\u003cp\u003eBefore this, I worked at Quantiphi, Scanta, and Mobile Programming LLC as a machine learning engineer and worked on speaker diarization, multimodal sentiment analysis, NLP augmentor, clinical ner, chatbot using AWS Lex and Dialogflow, customer care call analytics, neural machine translation.\u003c/p\u003e","title":"About"},{"content":"","permalink":"https://akshat4112.github.io/publication/","summary":"","title":"GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks"}]