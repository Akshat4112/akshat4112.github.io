[{"content":"","permalink":"http://localhost:63263/events/cyber_valley_ai_bootcamp_stuttgart_tubingen_zurich_2023/","summary":"","title":"Cyber Valley AI Startup Bootcamp"},{"content":"Paper\nAuthors: Akshat Gupta, Laxman Singh Tomar, Ridhima Garg\nAbstract Cyber attacks deceive machines into believing something that does not exist in the first place. However, there are some to which even humans fall prey. One such famous attack that attackers have used over the years to exploit the vulnerability of vision is known to be a Homoglyph attack. It employs a primary yet effective mechanism to create illegitimate domains that are hard to differentiate from legit ones. Moreover, as the difference is pretty indistinguishable for a user to notice, they cannot stop themselves from clicking on these homoglyph domain names.\nIn our work, we created GlyphNet, an image dataset that contains 4M domains, both real and homoglyphs. Additionally, we introduce a baseline method for homoglyph attack detection system using an attention-based convolutional Neural Network. We show that our model can reach state-of-the-art accuracy in detecting homoglyph attacks with a 0.93 AUC on our dataset.\nIntroduction In cyber security, attackers employ different attacks to infiltrate our systems and networks, with the objective varying from stealing crucial information to inflicting system damage. One such deceptive attack is the homoglyph attack, which involves an attacker trying to fool humans and computer systems by using characters and symbols that may appear visually similar to characters used in real domain and process names but are different.\nDataset Proposed Dataset We have proposed a dataset consisting of real and homoglyph domains. We obtained domains from the Domains Project, comprising 500M domains, restricting our work to 2M domains due to hardware restrictions.\nHomoglyph Creation Algorithm We created a novel algorithm for the generation of homoglyph domains to ensure that real homoglyphs are generated with randomness and closeness. To achieve this, we sample homoglyph noise characters using Gaussian sampling from the glyph pool.\nImage Generation Homoglyph attacks exploit the weakness of human vision to differentiate real from homoglyph domain names. We rendered images from the real and homoglyph strings generated via our algorithm.\nMethodology Experimentation Dataset and Metrics We split our dataset into train, validation, and test, with a ratio of 70:20:10, respectively. We use accuracy, precision, recall, and F1 score as our evaluation metrics, along with the AUC score.\nExperimental Settings For training, we used binary cross-entropy as a Loss Function and RMSProp Optimizer. The network is trained for 30 epochs with early stopping, using a batch size of 256.\nResults We evaluated our model on two unpaired datasets for domain names, achieving an accuracy of 0.93 and an F1-score of 0.93, outperforming other models.\nReferences Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473. Boor, V.; Overmars, M. H.; and Van Der Stappen, A. F. 1999. The Gaussian sampling strategy for probabilistic roadmap planners. In Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No. 99CH36288C), volume 2, 1018‚Äì1023. IEEE. Cheng, L.; Liu, F.; and Yao, D. 2017. Enterprise data breach: causes, challenges, prevention, and future directions. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 7(5): e1211. Chollet, F.; et al. 2015. Keras. Damerau, F. J. 1964. A technique for computer detection and correction of spelling errors. Communications of the ACM, 7(3): 171‚Äì176. Deng, J.; Dong, W.; Socher, R.; Li, L.-J.; Li, K.; and FeiFei, L. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, 248‚Äì255. Ieee. Ginsberg, A.; and Yu, C. 2018. Rapid homoglyph prediction and detection. In 2018 1st International Conference on Data Intelligence and Security (ICDIS), 17‚Äì23. IEEE. Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y. 2014. Generative adversarial nets. Advances in neural information processing systems, 27. He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770‚Äì778. Helms, M. M.; Ettkin, L. P.; and Morris, D. J. 2000. The risk of information compromise and approaches to prevention. The Journal of Strategic Information Systems, 9(1): 5‚Äì15. Hoffer, E.; and Ailon, N. 2015. Deep metric learning using triplet network. In International workshop on similarity-based pattern recognition, 84‚Äì92. Springer. Hong, J. 2012. The state of phishing attacks. Communications of the ACM, 55(1): 74‚Äì81. Isola, P.; Zhu, J.-Y.; Zhou, T.; and Efros, A. A. 2017. Imageto-image translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1125‚Äì1134. Citation @article{gupta2023glyphnet, title={GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks}, author={Gupta, Akshat and Tomar, Laxman Singh and Garg, Ridhima}, journal={arXiv preprint arXiv:2306.10392}, year={2023} } ","permalink":"http://localhost:63263/publications/glyphnet/","summary":"Paper\nAuthors: Akshat Gupta, Laxman Singh Tomar, Ridhima Garg\nAbstract Cyber attacks deceive machines into believing something that does not exist in the first place. However, there are some to which even humans fall prey. One such famous attack that attackers have used over the years to exploit the vulnerability of vision is known to be a Homoglyph attack. It employs a primary yet effective mechanism to create illegitimate domains that are hard to differentiate from legit ones.","title":"GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks"},{"content":"","permalink":"http://localhost:63263/events/mesh_hackathon_stuttgart_2023/","summary":"","title":"MESH Hackathon"},{"content":"Date of Event: September 6, 2019\nVenue: Dr. Akhilesh Das Gupta Institute of Technology \u0026amp; Management\nEvent Overview: In an exhilarating day filled with insights and hands-on activities, the Machine Learning workshop organized by Intel turned out to be a landmark event for aspiring ML enthusiasts. Our auditorium, buzzing with the energy of keen learners, became a crucible for innovation and deep understanding in the rapidly evolving field of Machine Learning.\nHighlights of the Session: Practical Learning Approach: The workshop kicked off by laying a solid foundation of Machine Learning concepts, employing a top-down teaching methodology. This approach, tailored to enhance student comprehension, was supplemented by easy-to-grasp visualizations, making complex theories accessible to all attendees.\nInteractive Sessions: A significant highlight was the interactive segment where students applied ML concepts in real-time. This \u0026rsquo;learning by doing\u0026rsquo; approach not only solidified their understanding but also sparked a curiosity to explore more.\nFocus on Modern AI Challenges: Beyond the basics, the workshop delved into the broader spectrum and future challenges of AI, presenting a realistic picture of the field today.\nHigh Engagement and Enthusiasm: The packed auditorium was a testament to the success of the workshop, with students showing a blend of contentment and eagerness to learn more.\nReflections: The day\u0026rsquo;s success was evident not just in the packed hall and the enthusiastic participation, but also in the heartwarming responses received on platforms like LinkedIn. This positive feedback has left us more energized and committed to organizing similar enriching events in the future.\nLooking Forward: The workshop has set a precedent for future sessions, highlighting the importance of practical, interactive learning in the field of Machine Learning and AI. We are excited about continuing this journey and contributing to the growth of aspiring Machine Learning professionals. Stay tuned for more updates and upcoming events in this space!\n","permalink":"http://localhost:63263/talks/intel_machine_learning_workshop/","summary":"Date of Event: September 6, 2019\nVenue: Dr. Akhilesh Das Gupta Institute of Technology \u0026amp; Management\nEvent Overview: In an exhilarating day filled with insights and hands-on activities, the Machine Learning workshop organized by Intel turned out to be a landmark event for aspiring ML enthusiasts. Our auditorium, buzzing with the energy of keen learners, became a crucible for innovation and deep understanding in the rapidly evolving field of Machine Learning.","title":"Recap of Intel's Machine Learning Workshop at Dr. Akhilesh Das Gupta Institute"},{"content":"","permalink":"http://localhost:63263/publications/deep_learning_with_tensorflow/","summary":"","title":"Hands-on Deep Learning with Tensorflow 2.0"},{"content":"Date of Event: May 05, 2020\nVenue: Online\nEvent Overview: In May 2020, Poornima University in Rajasthan hosted a groundbreaking workshop focusing on the Role of Natural Language Processing (NLP) in Healthcare. This event provided a unique platform for healthcare professionals, technologists, and students to explore the intersection of advanced linguistic technology and healthcare applications.\nHighlights of the Workshop: Introduction to NLP in Healthcare: The workshop started with an overview of NLP and its evolving role in the healthcare sector, emphasizing how it transforms patient care and medical data analysis.\nHands-On Sessions: Participants engaged in hands-on training, where they learned to apply NLP tools in various healthcare scenarios, such as patient data interpretation, medical record analysis, and more.\nExpert-Led Discussions: Leading experts in NLP and healthcare IT shared their insights on the latest trends, challenges, and advancements in the field, fostering a deeper understanding among attendees.\nCase Studies and Applications: The event featured several case studies demonstrating successful NLP applications in healthcare, highlighting its potential in improving diagnosis, treatment, and patient engagement.\nEthical Considerations: A key part of the workshop was dedicated to discussing the ethical implications of using NLP in healthcare, including data privacy and the importance of unbiased algorithms.\nParticipant Engagement: The workshop saw active participation from attendees, who were keen to understand how NLP can revolutionize healthcare delivery. The interactive format allowed for an exchange of ideas and stimulated discussions on future innovations in this space.\nConclusion: The workshop on the Role of NLP in Healthcare at Poornima University marked an important step towards bridging the gap between technology and healthcare. It opened new avenues for innovation and collaboration, setting the stage for future breakthroughs that can significantly enhance the quality and efficiency of healthcare services.\n","permalink":"http://localhost:63263/talks/nlp_in_healthcare/","summary":"Date of Event: May 05, 2020\nVenue: Online\nEvent Overview: In May 2020, Poornima University in Rajasthan hosted a groundbreaking workshop focusing on the Role of Natural Language Processing (NLP) in Healthcare. This event provided a unique platform for healthcare professionals, technologists, and students to explore the intersection of advanced linguistic technology and healthcare applications.\nHighlights of the Workshop: Introduction to NLP in Healthcare: The workshop started with an overview of NLP and its evolving role in the healthcare sector, emphasizing how it transforms patient care and medical data analysis.","title":"Role of Natural Language Processing in Healthcare"},{"content":"","permalink":"http://localhost:63263/events/smart_india_hackathon_2017/","summary":"","title":"Smart India Hackathon 2017: Minitry of Earth Sciences"},{"content":"Generative modeling is currently one of the most thrilling domains in deep learning research. Traditional models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) have already demonstrated impressive capabilities in synthetically generating realistic data, such as images and text. However, diffusion models is swiftly gaining prominence as a powerful model in the arena of high-quality and stable generative modeling. This blog explores diffusion models, examining their operational mechanisms, architectural designs, training processes, sampling methods, and the key advantages that position them at the forefront of generative AI.\nThe foundations of diffusion models were introduced in papers by Sohl-Dickstein et al. and Ho et al.\nHow Do Diffusion Models Work? Diffusion models function on a principal strategy of training a model to reverse a gradual process of data corruption, transitioning from a clean data point to pure noise and then back to clean data point.\nImage Source: Ho et al.\nForward Diffusion Process This corruption is executed through the forward diffusion process. It is characterized by the iterative addition of small quantities of Gaussian noise to the data \\(x_0\\) over \\(T\\) discrete time steps. This process is mathematically expressed as:\n\\[ x_t = \\sqrt{1 - \\beta_t} \\times x_{t-1} + \\sqrt{\\beta_t} \\times \\epsilon \\]\nIn this equation, \\(x_t\\) represents the partially corrupted data at time \\(t\\), \\(\\beta_t\\) is the noise parameter that controls variance, and \\(\\epsilon\\) signifies Gaussian noise. As \\(t\\) increases, \\(\\beta_t\\) is progressively annealed from a lower to higher value, methodically erasing the structure in \\(x_0\\) until it becomes unrecognizable noise \\(x_T\\).\nReverse Diffusion Process The core of the diffusion model is a neural network trained to precisely reverse this forward process. It accepts \\(x_t\\) as input and predicts \\(x_{t-1}\\), the less noisy version from the preceding step. By consecutively predicting each step in reverse, the model systematically denoises \\(x_T\\) back into a clear sample \\(x_0\\).\nA critical aspect of this training involves denoising score matching, where the model aims to predict the gradient of the log-probability of \\(x_{t-1}\\) given \\(x_t\\). This approach, relying on noise data from the forward process, is key to the model\u0026rsquo;s stable training.\nDiffusion Model Architectures Diffusion models commonly utilize convolutional neural networks, particularly U-Net architectures. The contracting and expanding paths in U-Nets facilitate both local and global attention to the noise, yielding high-quality outputs.\nConditional variants of these models integrate class embeddings at intermediate layers, allowing for controlled sampling of specific classes of data, like images of diverse objects.\nTraining Process Diffusion models are distinct in that they are trained using a denoising score matching loss rather than a standard likelihood loss. During training, the model is exposed only to artificially noised data from the forward process, never to clean data. This approach enables large-scale stable training and mitigates issues like mode collapse, common in likelihood-based models such as GANs, especially on diverse datasets. The iterative training on noise data endows diffusion models with robust generative capabilities.\nSampling Methods To generate samples from a trained diffusion model, one starts with pure noise \\(x_T\\) and progressively predicts \\(x_{T-1}\\), \\(x_{T-2}\\), and so on, using the model\u0026rsquo;s predicted denoising score at each step.\nThe number of sampling steps is crucial; approximately 1000 steps can recover fine details clearly, whereas fewer steps might result in distorted outputs. Post-processing techniques, such as upscaling, can further enhance the quality of the samples.\nAdvantages Over Other Models Diffusion models offer several advantages over existing generative models, making them a promising new direction in the field:\nSample Quality: The iterative denoising process facilitates the creation of high-resolution, clear samples that effectively capture the complexity of data. Training Stability: Exposure to only artificial noise data prevents collapse issues and enables scalable training. Flexible Control: Class-conditional variants offer significant control over sampling specific data types. Parallelizable Sampling: Each step in the sampling process can be efficiently parallelized across GPUs. Current Limitations Despite their advantages, diffusion models do face certain limitations:\nSampling is computationally intensive, requiring hundreds of passes. Numerous hyperparameters related to the noise schedule needs careful tuning. Class-conditional guidance is limited compared to the desired level of control. The Future of Generative AI Diffusion models are exceptionally promising as generative models due to both sample quality and training stability. With rapid innovations in architecture, hyperparameters, and sampling techniques, they represent the new frontier in generative modeling with vast potentials still to be unlocked. As research continues, we can expect diffusion models to become even more powerful and flexible generative tools.\n","permalink":"http://localhost:63263/posts/what_are_diffusion_models/","summary":"Generative modeling is currently one of the most thrilling domains in deep learning research. Traditional models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) have already demonstrated impressive capabilities in synthetically generating realistic data, such as images and text. However, diffusion models is swiftly gaining prominence as a powerful model in the arena of high-quality and stable generative modeling. This blog explores diffusion models, examining their operational mechanisms, architectural designs, training processes, sampling methods, and the key advantages that position them at the forefront of generative AI.","title":"What are Diffusion Models?"},{"content":" As machine learning systems are increasingly used in critical areas like finance, employment, and criminal justice, it\u0026rsquo;s essential to ensure these models are fair and do not discriminate against certain groups. In this post, I will explore the concept of fairness in machine learning.\nDefining Fairness Fairness in machine learning can be understood in several ways:\nGroup Fairness: This implies equal treatment or outcomes for different groups categorized by sensitive attributes like race or gender. For instance, ensuring a loan application system doesn\u0026rsquo;t have a higher false rejection rate for one gender compared to another.\nIndividual Fairness: This means that similar individuals should receive similar predictions or decisions, irrespective of their group membership. Two individuals with comparable financial backgrounds should get similar credit scores, regardless of their ethnicity or gender.\nCausal Fairness: Defined using causal modeling, it ensures similar predictions for individuals who would exhibit similar outcomes under different treatments. For example, a person\u0026rsquo;s chances of getting a job should not be influenced by their gender.\nSources of Unfairness Unfairness in machine learning models can arise from several factors:\nBiased Training Data: If the training data reflects historical human biases, the model will likely inherit these biases. Using Protected Variables: Direct use of attributes like race or gender in models can lead to disparate treatment. Proxy Variables: Models may learn to discriminate using variables correlated with protected attributes, like zip codes. Skewed Test Performance: Poor model performance on minority groups due to imbalanced datasets. Incorrect Similarity Metrics: Discriminatory definitions of similarity between individuals can introduce bias. Techniques to Improve Fairness Addressing unfairness involves strategies across the ML pipeline:\nPre-processing: Removing biases in training data and identifying proxy variables. In-processing: Modifying the model training process to incorporate fairness constraints. Post-processing: Applying techniques post-training to correct biases. Improved Evaluation: Using specific metrics to assess fairness in different contexts. Causal Modeling: Employing causal inference techniques to understand and mitigate biases. Real-World Example: Bias in Digital Recruitment Advertising A notable instance highlighting the need for fairness in AI was observed in digital recruitment advertising. An algorithm disproportionately showed high-salary job ads to men over women, influenced by biased historical data that reflected existing employment trends. This case underscores the importance of evaluating training data for biases and the necessity for ongoing algorithmic assessment to avoid reinforcing social inequalities.\nConclusion Achieving fairness in machine learning is a complex yet vital endeavor, requiring collaboration across various fields. With careful consideration and appropriate techniques, we can develop AI systems that are both ethical and equitable.\n","permalink":"http://localhost:63263/posts/fairness_in_machine_learning_/","summary":"As machine learning systems are increasingly used in critical areas like finance, employment, and criminal justice, it\u0026rsquo;s essential to ensure these models are fair and do not discriminate against certain groups. In this post, I will explore the concept of fairness in machine learning.\nDefining Fairness Fairness in machine learning can be understood in several ways:\nGroup Fairness: This implies equal treatment or outcomes for different groups categorized by sensitive attributes like race or gender.","title":"Fairness in Machine Learning"},{"content":"Date of Event: December 17, 2019\nVenue: Ujjain\nEvent Overview: Ujjain witnessed an enriching educational event in December 2019, with a workshop dedicated to introducing the fundamentals of Artificial Intelligence (AI). Designed for beginners and enthusiasts alike, this event served as a primer to the world of AI, attracting a diverse audience from students to professionals keen on understanding this cutting-edge technology.\nHighlights of the Workshop: Fundamentals of AI: The workshop focused on the core principles of AI, providing a comprehensive introduction to its basic concepts and terminologies.\nInteractive Learning Approach: To ensure a solid grasp of AI fundamentals, the workshop included interactive sessions and practical demonstrations, making complex topics accessible to all attendees.\nExpert Speakers: Knowledgeable speakers from the field of AI shared insights and real-world applications, offering a well-rounded perspective on the impact of AI in various industries.\nCollaborative Activities: Attendees participated in group activities designed to stimulate creative thinking and problem-solving in AI contexts.\nResource Sharing: The workshop also provided resources for further learning, encouraging participants to continue their AI education beyond the event.\nParticipant Experiences: The workshop was met with enthusiasm and curiosity, as attendees expressed their appreciation for the clear and engaging presentation of AI basics. Many participants noted how the workshop demystified AI and sparked their interest in exploring the field further.\nLooking Ahead: This introductory AI workshop has set the stage for more advanced discussions and learning opportunities in Ujjain. The positive response has paved the way for future events that will delve deeper into AI technologies and their applications.\nConclusion: The \u0026lsquo;Introduction to Artificial Intelligence\u0026rsquo; workshop in Ujjain was a significant step towards fostering a knowledgeable and skilled community ready to embrace AI advancements. As AI continues to evolve, Ujjain\u0026rsquo;s tech community is well-placed to be part of this transformative journey, equipped with the foundational knowledge imparted by this successful event.\n","permalink":"http://localhost:63263/talks/kips_artificial_intelligence_workshop/","summary":"Date of Event: December 17, 2019\nVenue: Ujjain\nEvent Overview: Ujjain witnessed an enriching educational event in December 2019, with a workshop dedicated to introducing the fundamentals of Artificial Intelligence (AI). Designed for beginners and enthusiasts alike, this event served as a primer to the world of AI, attracting a diverse audience from students to professionals keen on understanding this cutting-edge technology.\nHighlights of the Workshop: Fundamentals of AI: The workshop focused on the core principles of AI, providing a comprehensive introduction to its basic concepts and terminologies.","title":"Introduction to Artificial Intelligence Workshop in Ujjain"},{"content":"If you\u0026rsquo;ve been working with modern AI systems ‚Äî particularly in the realm of Large Language Models (LLMs), image embeddings, or recommendation engines ‚Äî you\u0026rsquo;ve probably heard of vector databases. But what are they really? And why is everyone in the ML community suddenly so excited about them?\nLet me break it down in simple terms, along with how I‚Äôve been exploring them in my own projects.\nüîç The Problem: Why Traditional Databases Fall Short Traditional databases (like PostgreSQL or MongoDB) are great when you‚Äôre dealing with exact matches or relational queries:\n‚ÄúFind all users from Stuttgart‚Äù ‚ÄúShow me orders placed in the last 30 days‚Äù But AI doesn\u0026rsquo;t speak in exact matches. For example:\n\u0026ldquo;Images similar to a cat\u0026rdquo; \u0026ldquo;Documents related to GDPR compliance\u0026rdquo; \u0026ldquo;People with similar resume embeddings\u0026rdquo; These are all semantic queries ‚Äî and you need a system that understands similarity, not just exact matches. That‚Äôs where vector databases come in.\nüß≠ What Is a Vector Database? A vector database is a specialized type of database designed to store and retrieve high-dimensional vectors ‚Äî the kind you get from neural network embeddings.\nFor instance:\nAn image processed by a CNN might become a 512-dimensional vector. A sentence embedding from BERT might be a 768-dimensional vector. A product recommendation engine might embed user behavior in 128 dimensions. These aren‚Äôt human-readable, but they carry meaning in a latent space. A vector database allows you to store, index, and search those vectors efficiently.\n‚öôÔ∏è How Do They Work? Here‚Äôs a simplified flow:\nGenerate Embeddings: Use a model like OpenAI‚Äôs embedding API, Hugging Face Transformers, or CLIP to convert your input (text/image/etc.) into a vector. Store the Vector: Save this vector along with metadata (e.g. document ID, title, tags) in the vector DB. Perform Similarity Search: When querying, your input is also converted into a vector, and the DB finds the closest vectors using metrics like cosine similarity or Euclidean distance. This is called Approximate Nearest Neighbor (ANN) search ‚Äî the core engine behind vector DBs.\nüì¶ Popular Vector Databases Here are a few tools I‚Äôve worked with or explored:\nPinecone: Fully managed and cloud-native, great for production LLM workflows. Weaviate: Open-source with hybrid search (keyword + vector). FAISS (Facebook AI Similarity Search): A C++/Python library for fast similarity search. Milvus: Industrial-grade open-source vector DB built for scale. Qdrant: Rust-based, developer-friendly, with REST and gRPC APIs. Chroma: Lightweight and ideal for quick local experiments or prototyping. üöÄ Real-World Use Cases Some practical examples I‚Äôve seen or built:\nRAG (Retrieval-Augmented Generation) pipelines: Retrieving the most relevant documents before feeding them to an LLM. Image Search: Finding visually similar images using CLIP embeddings. Voiceprint Matching: In a speaker diarization project, I embedded speaker audio and searched for similar embeddings. Semantic QA: Matching a question against a corpus of answers using dense embeddings instead of keywords. üß™ My Learnings \u0026amp; Tips Start Small: Use FAISS or Chroma locally before scaling to managed solutions like Pinecone. Hybrid Search Rocks: Combining vector similarity with keyword search (like in Weaviate or Elasticsearch) often yields better results. Fine-Tune Embeddings: Pretrained models work well, but fine-tuning with libraries like SentenceTransformers can significantly improve relevance. Storage + Speed Tradeoffs: ANN methods sacrifice some accuracy for speed ‚Äî you‚Äôll need to balance these based on your use case. üß© Final Thoughts Vector databases are not just a hype ‚Äî they‚Äôre a foundational layer in any serious GenAI system. From semantic search to recommendation and RAG, they enable the kind of \u0026ldquo;intelligent recall\u0026rdquo; that was previously hard to build at scale.\nIf you‚Äôre building anything involving embeddings, I strongly recommend giving one of these tools a try. Feel free to reach out if you‚Äôre stuck or want to nerd out about vector indexing strategies üòÑ\nThanks for reading! I‚Äôll be posting more about building scalable GenAI pipelines and multimodal systems ‚Äî stay tuned.\n‚Äî Akshat\n","permalink":"http://localhost:63263/posts/vector-databases/","summary":"An in-depth, beginner-friendly guide to vector databases, what they are, how they work, and where they fit in GenAI systems.","title":"What Are Vector Databases?"},{"content":"If you\u0026rsquo;re working with knowledge graphs, one term that keeps popping up is ontology. Sounds academic, right? Like something you\u0026rsquo;d find buried in a philosophy textbook.\nBut in the world of AI, data science, and search engines, an ontology is far from abstract ‚Äî it‚Äôs the blueprint that gives your knowledge graph meaning. Let‚Äôs break it down and explore how it all fits together.\nüß† What Is an Ontology (in AI)? In the simplest terms:\nAn ontology is a formal representation of concepts, relationships, and rules within a domain.\nIt tells your system:\nWhat things exist (like Person, Company, Product) What types of relationships they can have (worksFor, locatedIn, foundedBy) What rules govern those entities and their connections (e.g. ‚ÄúA Person can only work for a Company‚Äù) Think of it like a schema, but more expressive and logical ‚Äî like SQL schema meets logic programming.\nüîó How It Relates to Knowledge Graphs A knowledge graph is a collection of entities and their relationships, usually represented as: (subject) ‚Äî[predicate]‚Üí (object)\nExample: \u0026ldquo;Elon Musk\u0026rdquo; ‚Äî[CEO of]‚Üí \u0026ldquo;Tesla\u0026rdquo;\nBut how does the system know that ‚ÄúCEO of‚Äù is a valid relationship? Or that ‚ÄúElon Musk‚Äù is a Person and ‚ÄúTesla‚Äù is a Company?\nüëâ That‚Äôs where the ontology comes in.\nWithout an ontology, a knowledge graph is just a spaghetti mess of nodes and edges. The ontology gives it structure, semantics, and logic.\nüì¶ Example: Simple Ontology for a Business Graph Here‚Äôs a micro-ontology in plain English:\nClasses: Person, Company, Product Properties: worksFor(Person ‚Üí Company) foundedBy(Company ‚Üí Person) makes(Company ‚Üí Product) Rules: A Person can work for only one company. A Company must have at least one Product. Now, when you build your graph, this ontology acts as a guardrail. If someone tries to say a Product works for a Person, the system throws a semantic red flag üö©\nüß∞ Common Ontology Languages \u0026amp; Tools If you‚Äôre building real-world ontologies, you‚Äôll likely run into these tools and standards:\nOWL (Web Ontology Language) RDFS (RDF Schema) Prot√©g√© SHACL SPARQL These standards let you define your ontology and query your knowledge graph in ways that are both machine-readable and semantically rich.\nüß≠ Why Ontologies Matter Here‚Äôs why you should care about them if you\u0026rsquo;re working in AI or data science:\nSemantic Search: Understand user queries beyond keywords ‚Äî e.g. knowing that ‚ÄúBarack Obama‚Äôs wife‚Äù implies spouseOf. Data Integration: Merge messy, heterogeneous data using a shared structure. Explainability: Ontologies help machines reason about data ‚Äî e.g., infer that someone is a leader if they are a CEO of a Company. Interoperability: Use a global standard (like schema.org) to make your data web-friendly and machine-readable. üß™ In My Own Projects I‚Äôve used ontologies in:\nA healthcare project, where patient symptoms, diagnoses, and treatments were modeled using the SNOMED CT ontology. A personal finance KG, where Income, Expense, and Account were tightly defined ‚Äî enabling automated categorization and reasoning. Integrating RAG pipelines with structured knowledge graphs to improve retrieval precision using typed entity constraints. It‚Äôs honestly been a game-changer for building explainable AI systems.\nüß© Final Thoughts Ontologies are the brain behind a knowledge graph‚Äôs structure. They bring order to the chaos of data and let machines \u0026ldquo;understand\u0026rdquo; concepts and their context. If you‚Äôre venturing into semantic search, personalized recommendations, RAG systems, or even smart assistants ‚Äî investing time in ontology design is absolutely worth it.\nFeel free to ping me if you‚Äôre designing your first ontology or need help wrangling one into your GenAI pipeline. Happy graphing! üîçüß†\nMore posts on knowledge graphs, vector search, and GenAI systems coming soon.\n‚Äî Akshat\n","permalink":"http://localhost:63263/posts/ontology-in-knowledge-graphs/","summary":"A beginner-friendly explanation of what an ontology is, why it\u0026rsquo;s central to knowledge graphs, and how it helps machines understand complex relationships.","title":"What is an Ontology in a Knowledge Graph?"},{"content":"Knowledge graphs have revolutionized how we represent, store, and query complex information. They\u0026rsquo;ve become the backbone of modern search engines, recommendation systems, virtual assistants, and increasingly, large language models. But what exactly are they, and why have they become so essential?\nüîç What Is a Knowledge Graph? At its core, a knowledge graph is a network-structured knowledge base that integrates data by storing it as entities and relationships rather than in tables or documents. It represents real-world objects (people, places, products, concepts) and the connections between them in a way that captures semantic meaning.\nA knowledge graph consists of:\nEntities (nodes): Real-world objects like people, organizations, products, or concepts Relationships (edges): Connections between entities that represent how they relate to each other Properties: Attributes that describe entities or relationships For example, rather than storing the fact \u0026ldquo;Sundar Pichai is the CEO of Google\u0026rdquo; as text in a document or as rows in a database table, a knowledge graph would represent it as:\n(Sundar Pichai) ‚Äî[CEO of]‚Üí (Google)\nWhere both \u0026ldquo;Sundar Pichai\u0026rdquo; and \u0026ldquo;Google\u0026rdquo; are entities with their own properties, and \u0026ldquo;CEO of\u0026rdquo; is the relationship between them.\nüìä Knowledge Graphs vs. Traditional Databases Knowledge Graphs Traditional Databases Graph structure (nodes and edges) Table structure (rows and columns) Relationships are first-class citizens Relationships through foreign keys Schema flexible and evolving Schema rigid and predefined Optimized for connected data queries Optimized for structured queries Natural for representing real-world complexity Best for structured, predictable data üß© Key Components of Knowledge Graphs 1. Entities Entities are the \u0026ldquo;things\u0026rdquo; in your knowledge graph:\nPeople (Elon Musk, Marie Curie) Organizations (NASA, Microsoft) Places (Paris, Mount Everest) Concepts (Democracy, Quantum Physics) Products (iPhone, Tesla Model S) Each entity typically has a unique identifier and belongs to one or more entity types.\n2. Relationships Relationships connect entities and express how they relate to each other:\nPerson ‚Äî[works for]‚Üí Organization Person ‚Äî[invented]‚Üí Product Organization ‚Äî[located in]‚Üí Place Concept ‚Äî[subset of]‚Üí Concept 3. Properties/Attributes Properties provide additional information about entities or relationships:\nA Person entity might have properties like name, birth date, and nationality A relationship might have properties like start date, end date, or confidence score 4. Ontology/Schema As explained in my ontology post, an ontology defines the rules and structure of your knowledge graph:\nWhat types of entities exist What properties they can have What kinds of relationships are allowed between different entity types üõ†Ô∏è How Knowledge Graphs Are Built Creating a knowledge graph typically involves several processes:\n1. Entity Extraction Identifying entities from unstructured or semi-structured data sources:\nNamed Entity Recognition (NER) from text Structured data import from databases API integrations with existing knowledge sources 2. Relationship Extraction Determining how extracted entities relate to each other:\nPattern-based extraction from text Statistical models for relationship prediction Manual curation by domain experts 3. Entity Resolution Ensuring the same real-world entity is represented only once:\nDeduplication algorithms Identity resolution across sources Fuzzy matching techniques 4. Knowledge Fusion Combining and reconciling information from different sources:\nConflict resolution when sources disagree Confidence scoring for facts Provenance tracking to record where information came from üåê Famous Knowledge Graphs Several major knowledge graphs power services we use daily:\nGoogle Knowledge Graph\nPowers Google Search\u0026rsquo;s information boxes Contains over 500 billion facts about 5 billion entities Facebook Entity Graph\nPowers Facebook\u0026rsquo;s social network features Tracks relationships between people, places, interests Microsoft Academic Graph\nRepresents scientific publications, authors, institutions Contains over 230 million publications and 248 million authors Wikidata\nOpen collaborative knowledge base Contains over 100 million data items DBpedia\nStructured data extracted from Wikipedia Available in 125 different languages üíª Technologies for Building Knowledge Graphs Graph Databases Specialized databases optimized for storing and querying graph data:\nNeo4j: Popular open-source graph database with Cypher query language Amazon Neptune: Cloud-based graph database service TigerGraph: Distributed graph database for enterprise-scale graphs JanusGraph: Distributed graph database on top of storage backends like Cassandra Triple Stores Databases built specifically for RDF (Resource Description Framework) data:\nVirtuoso: Hybrid relational/graph database GraphDB: Enterprise-ready semantic graph database Stardog: Knowledge graph platform with reasoning capabilities Query Languages Languages specifically designed for graph data:\nSPARQL: Standard query language for RDF data Cypher: Neo4j\u0026rsquo;s query language Gremlin: Graph traversal language for property graphs üöÄ Applications of Knowledge Graphs The versatility of knowledge graphs has led to their adoption across numerous domains:\nSearch and Information Retrieval Enhanced search results with entity understanding Question answering systems Semantic search capabilities Recommendation Systems Content recommendation based on entity relationships Product recommendation in e-commerce Similar item discovery AI and Machine Learning Context provision for language models Training data for graph neural networks Fact verification for generative AI Enterprise Knowledge Management 360-degree customer views Organizational knowledge bases Supply chain optimization Healthcare and Life Sciences Drug discovery Disease networks Patient data integration üîÑ Knowledge Graphs in Modern AI Systems Knowledge graphs have become increasingly important in modern AI architectures:\nRetrieval-Augmented Generation (RAG) Knowledge graphs can provide structured, verifiable information to LLMs Enable more precise retrieval based on entity and relationship types Help bridge the gap between unstructured and structured data Reasoning and Explainability Provide transparent reasoning paths through explicit relationships Enable logical inference over factual data Support explainable AI by showing the path to conclusions Multimodal AI Connect concepts across text, images, video, and audio Provide structured context for multimodal understanding Enable reasoning across different types of information üíé Benefits of Knowledge Graphs 1. Contextual Understanding By explicitly modeling relationships, knowledge graphs provide context that\u0026rsquo;s difficult to capture in traditional databases or vector representations alone.\n2. Flexible Schema Evolution Unlike rigid database schemas, knowledge graphs can evolve organically as new types of entities and relationships are discovered.\n3. Complex Query Capabilities Knowledge graphs excel at multi-hop queries that would require multiple joins in relational databases: \u0026ldquo;Find all pharmaceutical companies that produce drugs targeting proteins involved in the COVID-19 infection pathway.\u0026rdquo;\n4. Inferencing and Reasoning With the right ontology, knowledge graphs support logical inference: If (Person A) ‚Äî[manages]‚Üí (Person B) and (Person B) ‚Äî[works in]‚Üí (Department C), then we can infer that (Person A) has authority over people in (Department C).\n5. Data Integration Knowledge graphs provide a natural way to integrate heterogeneous data from multiple sources with different schemas.\nüß™ Building Your First Knowledge Graph If you\u0026rsquo;re interested in creating your own knowledge graph, here\u0026rsquo;s a simplified approach:\nDefine Your Domain and Use Cases\nWhat questions should your knowledge graph answer? What entities and relationships matter most? Design a Simple Ontology\nDefine your main entity types Outline the key relationships between them Specify important attributes Start Small\nBegin with a manageable subset of data Manually curate high-quality seed data if possible Choose Your Technology Stack\nFor beginners: Neo4j is user-friendly For semantic web enthusiasts: RDF-based tools like GraphDB Incrementally Expand\nAdd new entity types and relationships as needed Incorporate additional data sources Refine your ontology based on emerging patterns üîÆ The Future of Knowledge Graphs Knowledge graphs continue to evolve in exciting directions:\n1. Integration with Vector Embeddings Hybrid approaches combining symbolic knowledge graphs with neural embeddings to get the best of both worlds.\n2. Temporal Knowledge Graphs Capturing how facts and relationships change over time for more accurate historical context.\n3. Collaborative Knowledge Graph Building Tools and platforms that allow domain experts to collectively build and maintain knowledge graphs.\n4. Automated Construction and Maintenance AI systems that can automatically extract entities and relationships from unstructured text and keep knowledge graphs updated.\n5. Knowledge-Augmented Neural Networks Neural architectures that explicitly incorporate knowledge graph structures for improved reasoning.\nüß† Final Thoughts Knowledge graphs represent one of the most powerful ways to organize and utilize information in the digital age. They bridge the gap between how humans conceptualize knowledge (as interconnected concepts) and how machines can process it efficiently.\nAs AI continues to advance, particularly with the rise of large language models, knowledge graphs offer a complementary approach that provides structure, verifiability, and explicit reasoning paths that statistical models alone cannot achieve.\nWhether you\u0026rsquo;re building a recommendation engine, enhancing search capabilities, or developing the next generation of AI assistants, knowledge graphs provide a robust foundation for representing the complex, interconnected nature of real-world knowledge.\nCheck out my related post on Ontologies in Knowledge Graphs to learn more about the semantic structure that gives knowledge graphs their power.\n‚Äî Akshat\n","permalink":"http://localhost:63263/posts/what-are-knowledge-graphs/","summary":"A comprehensive guide to knowledge graphs - what they are, how they work, their benefits, and their transformative role in modern AI and data systems.","title":"What Are Knowledge Graphs?"},{"content":"I\u0026rsquo;m a machine learning engineer and my research interests are in generative modelling, speech processing, text analysis, machine learning, and deep learning. Currently pursuing a master\u0026rsquo;s from the University of Stuttgart, my major is in computational linguistics.\nCurrent work Research work includes denoising diffusion on speaker embeddings, explainability of CRF-LSTM-based NER models, temporal and spatial word embeddings, and homoglyph detection using attention-based CNNs.\nMy work includes Before this, I worked at Quantiphi, Scanta, and Mobile Programming LLC as a machine learning engineer and worked on speaker diarization, multimodal sentiment analysis, NLP augmentor, clinical ner, chatbot using AWS Lex and Dialogflow, customer care call analytics, neural machine translation.\nBackground and history Previously I was an undergrad at APJ Abdul Kalam Technical University studying computers and maths. my major project was on \u0026ldquo;Automatic Catalogue Tagging using Deep Learning\u0026rdquo;. Other minor projects include an online examination system, school ERP, seawater quality monitoring system, and, online certificate generator. I\u0026rsquo;m from Agra and currently living in Stuttgart.\nOther Works Intel Software Innovator AAAI Reviewer Member of the Board of Studies at OP Jindal University Author with Packt publications Kaggle 3x expert, Top 1% of 300k+ Kaggle users Interests Table Tennis, Chess, Financial Markets, Quantum Physics ","permalink":"http://localhost:63263/about/","summary":"I\u0026rsquo;m a machine learning engineer and my research interests are in generative modelling, speech processing, text analysis, machine learning, and deep learning. Currently pursuing a master\u0026rsquo;s from the University of Stuttgart, my major is in computational linguistics.\nCurrent work Research work includes denoising diffusion on speaker embeddings, explainability of CRF-LSTM-based NER models, temporal and spatial word embeddings, and homoglyph detection using attention-based CNNs.\nMy work includes Before this, I worked at Quantiphi, Scanta, and Mobile Programming LLC as a machine learning engineer and worked on speaker diarization, multimodal sentiment analysis, NLP augmentor, clinical ner, chatbot using AWS Lex and Dialogflow, customer care call analytics, neural machine translation.","title":"About"},{"content":"","permalink":"http://localhost:63263/publication/","summary":"","title":"GlyphNet: Homoglyph domains dataset and detection using attention-based Convolutional Neural Networks"}]