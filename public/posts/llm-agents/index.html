<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=50281&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LLM Agents: Building AI Systems That Can Reason and Act | Akshat Gupta</title>
<meta name=keywords content="LLM,agents,deep-learning,AI,reinforcement-learning,decision-making,autonomous-systems"><meta name=description content="Understanding LLM Agents: The Future of Autonomous AI Systems Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter LLM Agents ‚Äî autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions."><meta name=author content><link rel=canonical href=http://localhost:50281/posts/llm-agents/><link crossorigin=anonymous href=/assets/css/stylesheet.e087fd1dc76e73a35ae6d7028ddc1ba41e0131e7f9b3a6e2d019a208e6d6c4b5.css integrity="sha256-4If9Hcduc6Na5tcCjdwbpB4BMef5s6bi0BmiCObWxLU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=http://localhost:50281/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:50281/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:50281/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:50281/apple-touch-icon.png><link rel=mask-icon href=http://localhost:50281/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:50281/posts/llm-agents/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css integrity=sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js integrity=sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-8YC2E5MW2M"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-8YC2E5MW2M")}</script><meta property="og:title" content="LLM Agents: Building AI Systems That Can Reason and Act"><meta property="og:description" content="Understanding LLM Agents: The Future of Autonomous AI Systems Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter LLM Agents ‚Äî autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:50281/posts/llm-agents/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-05T09:00:00+01:00"><meta property="article:modified_time" content="2025-05-05T09:00:00+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM Agents: Building AI Systems That Can Reason and Act"><meta name=twitter:description content="Understanding LLM Agents: The Future of Autonomous AI Systems Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter LLM Agents ‚Äî autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:50281/posts/"},{"@type":"ListItem","position":2,"name":"LLM Agents: Building AI Systems That Can Reason and Act","item":"http://localhost:50281/posts/llm-agents/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLM Agents: Building AI Systems That Can Reason and Act","name":"LLM Agents: Building AI Systems That Can Reason and Act","description":"Understanding LLM Agents: The Future of Autonomous AI Systems Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter LLM Agents ‚Äî autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions.","keywords":["LLM","agents","deep-learning","AI","reinforcement-learning","decision-making","autonomous-systems"],"articleBody":"Understanding LLM Agents: The Future of Autonomous AI Systems Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter LLM Agents ‚Äî autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions.\nIn this post, we‚Äôll explore what LLM agents are, how they work, and how to create and implement them in real-world applications.\nüß† What Are LLM Agents? An LLM Agent refers to an autonomous system built using a large language model, capable of interacting with environments, performing complex tasks, and making decisions based on user input. Unlike traditional models, which are limited to generating text based on inputs, LLM agents can take actions in a dynamic setting, execute workflows, and interact with external APIs, databases, and services.\nAn LLM Agent can:\nInterpret goals or instructions from users Plan a sequence of actions to achieve those goals Execute actions using tools or APIs Observe the results of those actions Reflect and adjust based on feedback Maintain long-term memory across interactions Key Features of LLM Agents: Autonomy: LLM agents can take action without continuous user intervention, executing tasks in an automated fashion. Adaptability: LLM agents can adapt to different environments and instructions, adjusting their actions based on input. Decision-Making: These agents can reason about tasks and make decisions, including breaking down large problems into smaller, manageable tasks. Integration: LLM agents can interface with external systems, like databases, APIs, and the web, to retrieve information and perform actions in real-time. Unlike a standard chat interface, which generates text only, agents can interface with external systems, manipulate data, browse the web, and sometimes control physical devices.\nüõ†Ô∏è How Do LLM Agents Work? LLM agents function by leveraging the capabilities of large language models in conjunction with external tools, frameworks, or environments. A fully-featured LLM agent typically consists of several key components:\n1. Foundation Model (Language Model Core) The core of an agent is the language model itself. The foundation model provides the reasoning, planning, and text generation capabilities. Models like GPT-4, Claude, or Llama 2 serve as the ‚Äúbrain‚Äù of the agent system. Its natural language understanding capabilities allow the agent to understand instructions in human language.\n2. Tool Use Framework Agents need to be able to use tools to interact with the world. This involves:\nTool definition: Specifying what tools are available Tool selection: Choosing which tool to use when Tool invocation: Properly formatting calls to tools Output processing: Interpreting the results of tool use Tools might include:\nWeb Services: Making HTTP requests to external APIs Databases: Querying or updating data in relational or NoSQL databases External Libraries: Accessing additional libraries or software packages to perform specialized tasks Code executors, calculators, and more 3. Memory Systems Effective agents require different types of memory:\nWorking memory: What‚Äôs relevant in the current context Semantic memory: Knowledge of facts, concepts, and relationships Episodic memory: Record of past conversations and actions Procedural memory: How to perform certain tasks In more advanced LLM agents, memory plays a crucial role. These agents may store information about past interactions, user preferences, or even the state of a task. Memory can either be:\nShort-term: Storing temporary information during a session. Long-term: Storing knowledge persistently, allowing the agent to retain information across sessions and continuously improve over time. 4. Planning and Reasoning Modules Agents must plan their actions and reason about their environment:\nTask decomposition: Breaking complex goals into manageable steps Decision making: Choosing between alternative approaches Self-reflection: Evaluating the success of actions and adjusting accordingly Meta-cognition: Reasoning about the agent‚Äôs own thought processes üíª Implementing LLM Agents: Frameworks and Approaches Several approaches and frameworks have emerged for building LLM agents:\nReAct: Reasoning and Acting The ReAct framework combines reasoning (thinking through a problem) with acting (taking steps toward a solution). It‚Äôs based on the observation that LLMs can generate both reasoning traces and action plans.\ndef react_agent(query, tools, max_steps=5): context = f\"User query: {query}\\n\\nAvailable tools: {tools_description(tools)}\" for step in range(max_steps): # Think: Generate reasoning about the current state thought = llm.generate(f\"{context}\\n\\nThought: Let me think about how to solve this...\") # Act: Decide on an action to take action = llm.generate(f\"{context}\\n{thought}\\n\\nAction: \") # Observe: Execute the action and observe results if action.startswith(\"FINISH\"): return action.replace(\"FINISH\", \"\") tool_name, tool_input = parse_action(action) observation = execute_tool(tools, tool_name, tool_input) # Update context with the new information context += f\"\\n{thought}\\n{action}\\n{observation}\" # Final answer after max steps return llm.generate(f\"{context}\\n\\nBased on the above, the final answer is:\") LangChain Agents LangChain provides a popular framework for building LLM agents with tool use capabilities:\nfrom langchain.agents import AgentType, initialize_agent from langchain.tools import Tool from langchain.llms import OpenAI # Define tools the agent can use tools = [ Tool( name=\"Search\", func=search_function, description=\"useful for when you need to search the internet\" ), Tool( name=\"Calculator\", func=calculator_function, description=\"useful for when you need to perform calculations\" ), ] # Initialize the agent llm = OpenAI(temperature=0) agent = initialize_agent( tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True ) # Run the agent agent.run(\"What is the square root of the current temperature in San Francisco?\") AutoGPT and BabyAGI For more autonomous agents, frameworks like AutoGPT and BabyAGI implement goal-driven systems that can create and manage their own subtasks:\nfrom autogpt import AutoGPT agent = AutoGPT( ai_name=\"Research Assistant\", ai_role=\"Conduct research on quantum computing breakthroughs\", memory=VectorMemory(), tools=[WebBrowser(), FileWriter(), Calculator(), GitHubReader()] ) # Start the agent with an initial goal agent.start( initial_goal=\"Create a comprehensive report on recent advancements in quantum error correction\" ) Basic Weather Agent Example Let‚Äôs look at a simpler example of how to create an LLM agent that performs a specific task: using a language model to interact with a weather API.\nimport openai import requests openai.api_key = \"your-api-key\" def query_language_model(prompt): response = openai.Completion.create( engine=\"gpt-4\", prompt=prompt, max_tokens=100 ) return response.choices[0].text.strip() def get_weather(city): api_key = \"your-weather-api-key\" url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}\u0026appid={api_key}\" response = requests.get(url) weather_data = response.json() if weather_data[\"cod\"] == 200: main = weather_data[\"main\"] temperature = main[\"temp\"] return f\"The current temperature in {city} is {temperature - 273.15:.2f}¬∞C.\" else: return \"Sorry, I couldn't fetch the weather data right now.\" def llm_agent_task(query): # Use GPT to decide if the user query is related to weather weather_prompt = f\"Is the following query related to weather: '{query}'\" is_weather_query = query_language_model(weather_prompt) if \"yes\" in is_weather_query.lower(): # Extract city name from query (simplified extraction) city = query.split(\"in\")[-1].strip() weather = get_weather(city) return weather else: return \"Sorry, I can only help with weather-related queries right now.\" # Example interaction user_query = \"What is the weather in Berlin today?\" response = llm_agent_task(user_query) print(response) In this example:\nThe agent first asks the language model if the query is weather-related If it is, the agent extracts the city name and fetches weather data from the API It then returns the weather information to the user Simple Memory Implementation A more advanced LLM agent would use memory to recall past interactions:\nclass SimpleMemory: def __init__(self): self.memory = {} def remember(self, key, value): self.memory[key] = value def recall(self, key): return self.memory.get(key, \"I don't remember that.\") # Example usage memory = SimpleMemory() memory.remember(\"favorite_color\", \"blue\") # Retrieving memory favorite_color = memory.recall(\"favorite_color\") print(favorite_color) # Outputs: blue üåü Advanced Agent Architectures Research and development in agent architectures has produced several sophisticated approaches:\n1. Multi-Agent Systems Multiple LLM agents can collaborate, each with specialized roles:\nCritic agents that evaluate plans and outputs Expert agents with domain-specific knowledge Coordinator agents that manage task distribution Debate agents that explore different perspectives For example, a system might use one agent as a researcher, one as a writer, one as an editor, and one as a fact-checker.\n# Pseudocode for a simple multi-agent debate def multi_agent_debate(question, num_rounds=3): agents = [ create_agent(\"Advocate\"), create_agent(\"Critic\"), create_agent(\"Mediator\") ] discussion = f\"Question: {question}\\n\" for round in range(num_rounds): for agent in agents: response = agent.generate(discussion) discussion += f\"\\n{agent.name}: {response}\" # Final synthesis by the mediator conclusion = agents[2].generate( f\"{discussion}\\n\\nBased on this discussion, the final answer is:\" ) return conclusion 2. Hierarchical Planning Complex tasks often benefit from hierarchical planning, where high-level goals are decomposed into subgoals:\ndef hierarchical_agent(goal): # High-level planning plan = llm.generate(f\"To achieve the goal: {goal}, I should break it down into steps:\") steps = parse_steps(plan) results = [] for step in steps: # For each step, either decompose further or execute directly if is_complex(step): sub_result = hierarchical_agent(step) # Recursively handle complex steps results.append(sub_result) else: action_result = execute_simple_action(step) results.append(action_result) # Synthesize results into a cohesive output return synthesize_results(results) 3. Reflexion: Self-Reflection and Improvement Agents can become more effective by reflecting on their performance and learning from mistakes:\ndef reflexion_agent(query, feedback_model, max_attempts=3): attempts = [] for attempt in range(max_attempts): # Generate a response response = agent.run(query) attempts.append(response) # Self-evaluate the response reflection = feedback_model.evaluate( query=query, response=response, criteria=[\"accuracy\", \"completeness\", \"reasoning\"] ) # If the response is satisfactory, return it if reflection.score \u003e 0.8: return response # Otherwise, learn from the reflection agent.update_with_feedback(reflection) # Return the best attempt according to the feedback model best_attempt = max(attempts, key=lambda a: feedback_model.evaluate(query, a).score) return best_attempt üìä Evaluating LLM Agents Evaluating agent performance is challenging due to the complexity and diversity of tasks they might perform. Some evaluation approaches include:\nBenchmark Tasks WebShop: Testing if an agent can follow instructions to purchase items online ALFWorld: Having agents navigate text-based environments HotPotQA: Multi-step question answering requiring reasoning Evaluation Metrics Success rate: Did the agent accomplish the goal? Efficiency: How many steps or how much time was required? Autonomy: How much human intervention was needed? Exploration: How effectively did the agent explore alternatives? Robustness: How well does the agent handle unexpected situations? üöÄ Applications of LLM Agents The potential applications of LLM agents span numerous domains:\nResearch Assistants Agents can help researchers by searching literature, summarizing papers, generating hypotheses, and designing experiments.\nPersonal Assistants Agents can manage calendars, book appointments, organize information, and automate routine tasks based on user preferences.\nSoftware Development Coding agents can write, test, and debug code, as well as implement features based on specifications.\nBusiness Automation Agents can process documents, generate reports, analyze data, and automate workflows in business contexts.\nEducation and Tutoring Educational agents can provide personalized tutoring, answer questions, and adapt content to a student‚Äôs learning style.\nCustomer Support These agents can handle customer service tasks, from answering FAQs to resolving complaints and managing customer interactions.\nHealthcare LLM agents can assist in diagnosing conditions, interpreting medical records, and scheduling appointments.\nüß™ Challenges and Future Directions Despite rapid progress, several challenges remain in developing effective LLM agents:\n1. Reliability and Safety Agents need guardrails to ensure they don‚Äôt:\nTake harmful actions Execute unintended operations Leak sensitive information Generate misleading content 2. Scalability Current approaches often struggle with:\nVery long-term planning Complex multi-step tasks Large-scale knowledge integration Computational efficiency 3. Integration with Specialized Tools Building agents that can effectively:\nInterface with domain-specific software Control robotic systems Work with specialized scientific tools Handle multimodal inputs and outputs 4. Ambiguity in Queries LLM agents often face difficulties when handling ambiguous queries. Without additional context, they may generate incorrect or irrelevant responses.\n5. Resource Consumption Running LLM agents, especially those that require continuous interaction with large models and external services, can be resource-intensive.\n6. Ethical Concerns There are ethical implications regarding the use of LLM agents in decision-making, privacy concerns, and the potential for misuse. Responsible AI practices and transparency in the model‚Äôs actions are essential.\nüíº Building Your Own Agent: A Practical Example Let‚Äôs build a simple research agent that can search for information and summarize findings:\nimport os from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser from langchain.prompts import StringPromptTemplate from langchain import OpenAI, SerpAPIWrapper, LLMChain from typing import List, Union, Dict, Any import re # Set up search tool search = SerpAPIWrapper() tools = [ Tool( name=\"Search\", func=search.run, description=\"useful for when you need to search for information on the internet\" ) ] # Set up the prompt template template = \"\"\"You are a research assistant. You have access to the following tools: {tools} Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tool_names}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now know the final answer Final Answer: the final answer to the original input question Begin! Question: {input} Thought: \"\"\" class CustomPromptTemplate(StringPromptTemplate): template: str tools: List[Tool] def format(self, **kwargs) -\u003e str: intermediate_steps = kwargs.pop(\"intermediate_steps\", []) thoughts = \"\" for action, observation in intermediate_steps: thoughts += action.log thoughts += f\"\\nObservation: {observation}\\nThought: \" kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools]) kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools]) return self.template.format(**kwargs) + thoughts prompt = CustomPromptTemplate( template=template, tools=tools, input_variables=[\"input\", \"intermediate_steps\"] ) class CustomOutputParser(AgentOutputParser): def parse(self, llm_output: str) -\u003e Union[Dict[str, Any], str]: if \"Final Answer:\" in llm_output: return {\"output\": llm_output.split(\"Final Answer:\")[-1].strip()} regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\" match = re.search(regex, llm_output, re.DOTALL) if not match: return {\"output\": llm_output} action = match.group(1).strip() action_input = match.group(2).strip(\" \") return {\"action\": action, \"action_input\": action_input} output_parser = CustomOutputParser() llm = OpenAI(temperature=0) llm_chain = LLMChain(llm=llm, prompt=prompt) agent = LLMSingleActionAgent( llm_chain=llm_chain, output_parser=output_parser, stop=[\"\\nObservation:\"], allowed_tools=[tool.name for tool in tools] ) agent_executor = AgentExecutor.from_agent_and_tools( agent=agent, tools=tools, verbose=True ) # Example usage result = agent_executor.run(\"What are the latest developments in quantum computing?\") print(result) üß† Final Thoughts LLM agents represent a step change in AI capabilities, moving from models that merely respond to queries to systems that can actively pursue goals. While we‚Äôre still in the early days of this technology, the rapid progress suggests we‚Äôre approaching an era of increasingly autonomous and capable AI assistants.\nThe most effective agents will likely combine the strengths of LLMs‚Äîreasoning, world knowledge, and flexibility‚Äîwith specialized tools and robust planning frameworks. As these technologies mature, we can expect to see agents that can tackle increasingly complex and open-ended tasks, from scientific research to creative projects and beyond.\nBuilding effective agents remains a challenging engineering problem, balancing power with reliability, autonomy with control, and capability with safety. The frameworks and approaches outlined in this post provide a starting point, but there‚Äôs still significant room for innovation in the design and implementation of these systems.\nWith advancements in large language models and AI technology, the potential for LLM agents will continue to expand, bringing us closer to fully autonomous, intelligent systems that can understand our needs and act on our behalf with increasing competence and reliability.\n‚Äî Akshat\n","wordCount":"2403","inLanguage":"en","datePublished":"2025-05-05T09:00:00+01:00","dateModified":"2025-05-05T09:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:50281/posts/llm-agents/"},"publisher":{"@type":"Organization","name":"Akshat Gupta","logo":{"@type":"ImageObject","url":"http://localhost:50281/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:50281/ accesskey=h title="Akshat Gupta (Alt + H)">Akshat Gupta</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch></ul></div></div><ul id=menu><li><a href=http://localhost:50281/posts title=Posts><span>Posts</span></a></li><li><a href=http://localhost:50281/publications/ title=Publications><span>Publications</span></a></li><li><a href=http://localhost:50281/talks/ title=Talks><span>Talks</span></a></li><li><a href=http://localhost:50281/events/ title=Events><span>Events</span></a></li><li><a href=http://localhost:50281/about/ title=About><span>About</span></a></li><li><a href="https://drive.google.com/file/d/1Qj6kaZXM40ixUgOAewhZlTj57piWERSw/view?usp=drive_link" title=CV><span>CV</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:50281/>Home</a>&nbsp;¬ª&nbsp;<a href=http://localhost:50281/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">LLM Agents: Building AI Systems That Can Reason and Act</h1><div class=post-meta><span title='2025-05-05 09:00:00 +0100 +0100'>May 5, 2025</span>&nbsp;¬∑&nbsp;12 min</div></header><div class=post-content><h1 id=understanding-llm-agents-the-future-of-autonomous-ai-systems>Understanding LLM Agents: The Future of Autonomous AI Systems<a hidden class=anchor aria-hidden=true href=#understanding-llm-agents-the-future-of-autonomous-ai-systems>#</a></h1><p>Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter <strong>LLM Agents</strong> ‚Äî autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions.</p><p>In this post, we&rsquo;ll explore what LLM agents are, how they work, and how to create and implement them in real-world applications.</p><h2 id=-what-are-llm-agents>üß† What Are LLM Agents?<a hidden class=anchor aria-hidden=true href=#-what-are-llm-agents>#</a></h2><p>An <strong>LLM Agent</strong> refers to an autonomous system built using a large language model, capable of interacting with environments, performing complex tasks, and making decisions based on user input. Unlike traditional models, which are limited to generating text based on inputs, LLM agents can take actions in a dynamic setting, execute workflows, and interact with external APIs, databases, and services.</p><p>An LLM Agent can:</p><ol><li><strong>Interpret goals or instructions</strong> from users</li><li><strong>Plan a sequence of actions</strong> to achieve those goals</li><li><strong>Execute actions</strong> using tools or APIs</li><li><strong>Observe the results</strong> of those actions</li><li><strong>Reflect and adjust</strong> based on feedback</li><li><strong>Maintain long-term memory</strong> across interactions</li></ol><h3 id=key-features-of-llm-agents>Key Features of LLM Agents:<a hidden class=anchor aria-hidden=true href=#key-features-of-llm-agents>#</a></h3><ul><li><strong>Autonomy</strong>: LLM agents can take action without continuous user intervention, executing tasks in an automated fashion.</li><li><strong>Adaptability</strong>: LLM agents can adapt to different environments and instructions, adjusting their actions based on input.</li><li><strong>Decision-Making</strong>: These agents can reason about tasks and make decisions, including breaking down large problems into smaller, manageable tasks.</li><li><strong>Integration</strong>: LLM agents can interface with external systems, like databases, APIs, and the web, to retrieve information and perform actions in real-time.</li></ul><p>Unlike a standard chat interface, which generates text only, agents can interface with external systems, manipulate data, browse the web, and sometimes control physical devices.</p><h2 id=-how-do-llm-agents-work>üõ†Ô∏è How Do LLM Agents Work?<a hidden class=anchor aria-hidden=true href=#-how-do-llm-agents-work>#</a></h2><p>LLM agents function by leveraging the capabilities of large language models in conjunction with external tools, frameworks, or environments. A fully-featured LLM agent typically consists of several key components:</p><h3 id=1-foundation-model-language-model-core>1. Foundation Model (Language Model Core)<a hidden class=anchor aria-hidden=true href=#1-foundation-model-language-model-core>#</a></h3><p>The core of an agent is the language model itself. The foundation model provides the reasoning, planning, and text generation capabilities. Models like GPT-4, Claude, or Llama 2 serve as the &ldquo;brain&rdquo; of the agent system. Its natural language understanding capabilities allow the agent to understand instructions in human language.</p><h3 id=2-tool-use-framework>2. Tool Use Framework<a hidden class=anchor aria-hidden=true href=#2-tool-use-framework>#</a></h3><p>Agents need to be able to use tools to interact with the world. This involves:</p><ul><li><strong>Tool definition</strong>: Specifying what tools are available</li><li><strong>Tool selection</strong>: Choosing which tool to use when</li><li><strong>Tool invocation</strong>: Properly formatting calls to tools</li><li><strong>Output processing</strong>: Interpreting the results of tool use</li></ul><p>Tools might include:</p><ul><li><strong>Web Services</strong>: Making HTTP requests to external APIs</li><li><strong>Databases</strong>: Querying or updating data in relational or NoSQL databases</li><li><strong>External Libraries</strong>: Accessing additional libraries or software packages to perform specialized tasks</li><li>Code executors, calculators, and more</li></ul><h3 id=3-memory-systems>3. Memory Systems<a hidden class=anchor aria-hidden=true href=#3-memory-systems>#</a></h3><p>Effective agents require different types of memory:</p><ul><li><strong>Working memory</strong>: What&rsquo;s relevant in the current context</li><li><strong>Semantic memory</strong>: Knowledge of facts, concepts, and relationships</li><li><strong>Episodic memory</strong>: Record of past conversations and actions</li><li><strong>Procedural memory</strong>: How to perform certain tasks</li></ul><p>In more advanced LLM agents, memory plays a crucial role. These agents may store information about past interactions, user preferences, or even the state of a task. Memory can either be:</p><ul><li><strong>Short-term</strong>: Storing temporary information during a session.</li><li><strong>Long-term</strong>: Storing knowledge persistently, allowing the agent to retain information across sessions and continuously improve over time.</li></ul><h3 id=4-planning-and-reasoning-modules>4. Planning and Reasoning Modules<a hidden class=anchor aria-hidden=true href=#4-planning-and-reasoning-modules>#</a></h3><p>Agents must plan their actions and reason about their environment:</p><ul><li><strong>Task decomposition</strong>: Breaking complex goals into manageable steps</li><li><strong>Decision making</strong>: Choosing between alternative approaches</li><li><strong>Self-reflection</strong>: Evaluating the success of actions and adjusting accordingly</li><li><strong>Meta-cognition</strong>: Reasoning about the agent&rsquo;s own thought processes</li></ul><h2 id=-implementing-llm-agents-frameworks-and-approaches>üíª Implementing LLM Agents: Frameworks and Approaches<a hidden class=anchor aria-hidden=true href=#-implementing-llm-agents-frameworks-and-approaches>#</a></h2><p>Several approaches and frameworks have emerged for building LLM agents:</p><h3 id=react-reasoning-and-acting>ReAct: Reasoning and Acting<a hidden class=anchor aria-hidden=true href=#react-reasoning-and-acting>#</a></h3><p>The ReAct framework combines reasoning (thinking through a problem) with acting (taking steps toward a solution). It&rsquo;s based on the observation that LLMs can generate both reasoning traces and action plans.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>react_agent</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>tools</span><span class=p>,</span> <span class=n>max_steps</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>context</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;User query: </span><span class=si>{</span><span class=n>query</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>Available tools: </span><span class=si>{</span><span class=n>tools_description</span><span class=p>(</span><span class=n>tools</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_steps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Think: Generate reasoning about the current state</span>
</span></span><span class=line><span class=cl>        <span class=n>thought</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>context</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>Thought: Let me think about how to solve this...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Act: Decide on an action to take</span>
</span></span><span class=line><span class=cl>        <span class=n>action</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>context</span><span class=si>}</span><span class=se>\n</span><span class=si>{</span><span class=n>thought</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>Action: &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Observe: Execute the action and observe results</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>action</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=s2>&#34;FINISH&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>action</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;FINISH&#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>        <span class=n>tool_name</span><span class=p>,</span> <span class=n>tool_input</span> <span class=o>=</span> <span class=n>parse_action</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>observation</span> <span class=o>=</span> <span class=n>execute_tool</span><span class=p>(</span><span class=n>tools</span><span class=p>,</span> <span class=n>tool_name</span><span class=p>,</span> <span class=n>tool_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Update context with the new information</span>
</span></span><span class=line><span class=cl>        <span class=n>context</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=n>thought</span><span class=si>}</span><span class=se>\n</span><span class=si>{</span><span class=n>action</span><span class=si>}</span><span class=se>\n</span><span class=si>{</span><span class=n>observation</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Final answer after max steps</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>llm</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>context</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>Based on the above, the final answer is:&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=langchain-agents>LangChain Agents<a hidden class=anchor aria-hidden=true href=#langchain-agents>#</a></h3><p>LangChain provides a popular framework for building LLM agents with tool use capabilities:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>AgentType</span><span class=p>,</span> <span class=n>initialize_agent</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.tools</span> <span class=kn>import</span> <span class=n>Tool</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.llms</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define tools the agent can use</span>
</span></span><span class=line><span class=cl><span class=n>tools</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=n>Tool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;Search&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>func</span><span class=o>=</span><span class=n>search_function</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;useful for when you need to search the internet&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>Tool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;Calculator&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>func</span><span class=o>=</span><span class=n>calculator_function</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;useful for when you need to perform calculations&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the agent</span>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>agent</span> <span class=o>=</span> <span class=n>initialize_agent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=p>,</span> <span class=n>llm</span><span class=p>,</span> <span class=n>agent</span><span class=o>=</span><span class=n>AgentType</span><span class=o>.</span><span class=n>ZERO_SHOT_REACT_DESCRIPTION</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Run the agent</span>
</span></span><span class=line><span class=cl><span class=n>agent</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=s2>&#34;What is the square root of the current temperature in San Francisco?&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=autogpt-and-babyagi>AutoGPT and BabyAGI<a hidden class=anchor aria-hidden=true href=#autogpt-and-babyagi>#</a></h3><p>For more autonomous agents, frameworks like AutoGPT and BabyAGI implement goal-driven systems that can create and manage their own subtasks:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>autogpt</span> <span class=kn>import</span> <span class=n>AutoGPT</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>agent</span> <span class=o>=</span> <span class=n>AutoGPT</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>ai_name</span><span class=o>=</span><span class=s2>&#34;Research Assistant&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>ai_role</span><span class=o>=</span><span class=s2>&#34;Conduct research on quantum computing breakthroughs&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>memory</span><span class=o>=</span><span class=n>VectorMemory</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=o>=</span><span class=p>[</span><span class=n>WebBrowser</span><span class=p>(),</span> <span class=n>FileWriter</span><span class=p>(),</span> <span class=n>Calculator</span><span class=p>(),</span> <span class=n>GitHubReader</span><span class=p>()]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Start the agent with an initial goal</span>
</span></span><span class=line><span class=cl><span class=n>agent</span><span class=o>.</span><span class=n>start</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>initial_goal</span><span class=o>=</span><span class=s2>&#34;Create a comprehensive report on recent advancements in quantum error correction&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h3 id=basic-weather-agent-example>Basic Weather Agent Example<a hidden class=anchor aria-hidden=true href=#basic-weather-agent-example>#</a></h3><p>Let&rsquo;s look at a simpler example of how to create an LLM agent that performs a specific task: using a language model to interact with a weather API.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>openai</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>openai</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=s2>&#34;your-api-key&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>query_language_model</span><span class=p>(</span><span class=n>prompt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>Completion</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>engine</span><span class=o>=</span><span class=s2>&#34;gpt-4&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=n>prompt</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_weather</span><span class=p>(</span><span class=n>city</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>api_key</span> <span class=o>=</span> <span class=s2>&#34;your-weather-api-key&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>url</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;http://api.openweathermap.org/data/2.5/weather?q=</span><span class=si>{</span><span class=n>city</span><span class=si>}</span><span class=s2>&amp;appid=</span><span class=si>{</span><span class=n>api_key</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>weather_data</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>weather_data</span><span class=p>[</span><span class=s2>&#34;cod&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=mi>200</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>main</span> <span class=o>=</span> <span class=n>weather_data</span><span class=p>[</span><span class=s2>&#34;main&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span> <span class=o>=</span> <span class=n>main</span><span class=p>[</span><span class=s2>&#34;temp&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=sa>f</span><span class=s2>&#34;The current temperature in </span><span class=si>{</span><span class=n>city</span><span class=si>}</span><span class=s2> is </span><span class=si>{</span><span class=n>temperature</span> <span class=o>-</span> <span class=mf>273.15</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>¬∞C.&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;Sorry, I couldn&#39;t fetch the weather data right now.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>llm_agent_task</span><span class=p>(</span><span class=n>query</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Use GPT to decide if the user query is related to weather</span>
</span></span><span class=line><span class=cl>    <span class=n>weather_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;Is the following query related to weather: &#39;</span><span class=si>{</span><span class=n>query</span><span class=si>}</span><span class=s2>&#39;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>is_weather_query</span> <span class=o>=</span> <span class=n>query_language_model</span><span class=p>(</span><span class=n>weather_prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;yes&#34;</span> <span class=ow>in</span> <span class=n>is_weather_query</span><span class=o>.</span><span class=n>lower</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=c1># Extract city name from query (simplified extraction)</span>
</span></span><span class=line><span class=cl>        <span class=n>city</span> <span class=o>=</span> <span class=n>query</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;in&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>weather</span> <span class=o>=</span> <span class=n>get_weather</span><span class=p>(</span><span class=n>city</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>weather</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;Sorry, I can only help with weather-related queries right now.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Example interaction</span>
</span></span><span class=line><span class=cl><span class=n>user_query</span> <span class=o>=</span> <span class=s2>&#34;What is the weather in Berlin today?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>llm_agent_task</span><span class=p>(</span><span class=n>user_query</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span></code></pre></div><p>In this example:</p><ol><li>The agent first asks the language model if the query is weather-related</li><li>If it is, the agent extracts the city name and fetches weather data from the API</li><li>It then returns the weather information to the user</li></ol><h3 id=simple-memory-implementation>Simple Memory Implementation<a hidden class=anchor aria-hidden=true href=#simple-memory-implementation>#</a></h3><p>A more advanced LLM agent would use memory to recall past interactions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>SimpleMemory</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>memory</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>remember</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>memory</span><span class=p>[</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>value</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>recall</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>key</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>memory</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>key</span><span class=p>,</span> <span class=s2>&#34;I don&#39;t remember that.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Example usage</span>
</span></span><span class=line><span class=cl><span class=n>memory</span> <span class=o>=</span> <span class=n>SimpleMemory</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>memory</span><span class=o>.</span><span class=n>remember</span><span class=p>(</span><span class=s2>&#34;favorite_color&#34;</span><span class=p>,</span> <span class=s2>&#34;blue&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Retrieving memory</span>
</span></span><span class=line><span class=cl><span class=n>favorite_color</span> <span class=o>=</span> <span class=n>memory</span><span class=o>.</span><span class=n>recall</span><span class=p>(</span><span class=s2>&#34;favorite_color&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>favorite_color</span><span class=p>)</span>  <span class=c1># Outputs: blue</span>
</span></span></code></pre></div><h2 id=-advanced-agent-architectures>üåü Advanced Agent Architectures<a hidden class=anchor aria-hidden=true href=#-advanced-agent-architectures>#</a></h2><p>Research and development in agent architectures has produced several sophisticated approaches:</p><h3 id=1-multi-agent-systems>1. Multi-Agent Systems<a hidden class=anchor aria-hidden=true href=#1-multi-agent-systems>#</a></h3><p>Multiple LLM agents can collaborate, each with specialized roles:</p><ul><li><strong>Critic agents</strong> that evaluate plans and outputs</li><li><strong>Expert agents</strong> with domain-specific knowledge</li><li><strong>Coordinator agents</strong> that manage task distribution</li><li><strong>Debate agents</strong> that explore different perspectives</li></ul><p>For example, a system might use one agent as a researcher, one as a writer, one as an editor, and one as a fact-checker.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Pseudocode for a simple multi-agent debate</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>multi_agent_debate</span><span class=p>(</span><span class=n>question</span><span class=p>,</span> <span class=n>num_rounds</span><span class=o>=</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>agents</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>create_agent</span><span class=p>(</span><span class=s2>&#34;Advocate&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>create_agent</span><span class=p>(</span><span class=s2>&#34;Critic&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>create_agent</span><span class=p>(</span><span class=s2>&#34;Mediator&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>discussion</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;Question: </span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=se>\n</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=nb>round</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_rounds</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>agent</span> <span class=ow>in</span> <span class=n>agents</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>response</span> <span class=o>=</span> <span class=n>agent</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>discussion</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>discussion</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=n>agent</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>response</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Final synthesis by the mediator</span>
</span></span><span class=line><span class=cl>    <span class=n>conclusion</span> <span class=o>=</span> <span class=n>agents</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>discussion</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>Based on this discussion, the final answer is:&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>conclusion</span>
</span></span></code></pre></div><h3 id=2-hierarchical-planning>2. Hierarchical Planning<a hidden class=anchor aria-hidden=true href=#2-hierarchical-planning>#</a></h3><p>Complex tasks often benefit from hierarchical planning, where high-level goals are decomposed into subgoals:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>hierarchical_agent</span><span class=p>(</span><span class=n>goal</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># High-level planning</span>
</span></span><span class=line><span class=cl>    <span class=n>plan</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;To achieve the goal: </span><span class=si>{</span><span class=n>goal</span><span class=si>}</span><span class=s2>, I should break it down into steps:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>steps</span> <span class=o>=</span> <span class=n>parse_steps</span><span class=p>(</span><span class=n>plan</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=n>steps</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># For each step, either decompose further or execute directly</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>is_complex</span><span class=p>(</span><span class=n>step</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>sub_result</span> <span class=o>=</span> <span class=n>hierarchical_agent</span><span class=p>(</span><span class=n>step</span><span class=p>)</span>  <span class=c1># Recursively handle complex steps</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>sub_result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>action_result</span> <span class=o>=</span> <span class=n>execute_simple_action</span><span class=p>(</span><span class=n>step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>action_result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Synthesize results into a cohesive output</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>synthesize_results</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=3-reflexion-self-reflection-and-improvement>3. Reflexion: Self-Reflection and Improvement<a hidden class=anchor aria-hidden=true href=#3-reflexion-self-reflection-and-improvement>#</a></h3><p>Agents can become more effective by reflecting on their performance and learning from mistakes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>reflexion_agent</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>feedback_model</span><span class=p>,</span> <span class=n>max_attempts</span><span class=o>=</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>attempts</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>attempt</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_attempts</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Generate a response</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=n>agent</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attempts</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Self-evaluate the response</span>
</span></span><span class=line><span class=cl>        <span class=n>reflection</span> <span class=o>=</span> <span class=n>feedback_model</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>query</span><span class=o>=</span><span class=n>query</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>            <span class=n>response</span><span class=o>=</span><span class=n>response</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>criteria</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;accuracy&#34;</span><span class=p>,</span> <span class=s2>&#34;completeness&#34;</span><span class=p>,</span> <span class=s2>&#34;reasoning&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># If the response is satisfactory, return it</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reflection</span><span class=o>.</span><span class=n>score</span> <span class=o>&gt;</span> <span class=mf>0.8</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>response</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>        <span class=c1># Otherwise, learn from the reflection</span>
</span></span><span class=line><span class=cl>        <span class=n>agent</span><span class=o>.</span><span class=n>update_with_feedback</span><span class=p>(</span><span class=n>reflection</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Return the best attempt according to the feedback model</span>
</span></span><span class=line><span class=cl>    <span class=n>best_attempt</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>attempts</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>a</span><span class=p>:</span> <span class=n>feedback_model</span><span class=o>.</span><span class=n>evaluate</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>a</span><span class=p>)</span><span class=o>.</span><span class=n>score</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>best_attempt</span>
</span></span></code></pre></div><h2 id=-evaluating-llm-agents>üìä Evaluating LLM Agents<a hidden class=anchor aria-hidden=true href=#-evaluating-llm-agents>#</a></h2><p>Evaluating agent performance is challenging due to the complexity and diversity of tasks they might perform. Some evaluation approaches include:</p><h3 id=benchmark-tasks>Benchmark Tasks<a hidden class=anchor aria-hidden=true href=#benchmark-tasks>#</a></h3><ul><li><strong>WebShop</strong>: Testing if an agent can follow instructions to purchase items online</li><li><strong>ALFWorld</strong>: Having agents navigate text-based environments</li><li><strong>HotPotQA</strong>: Multi-step question answering requiring reasoning</li></ul><h3 id=evaluation-metrics>Evaluation Metrics<a hidden class=anchor aria-hidden=true href=#evaluation-metrics>#</a></h3><ul><li><strong>Success rate</strong>: Did the agent accomplish the goal?</li><li><strong>Efficiency</strong>: How many steps or how much time was required?</li><li><strong>Autonomy</strong>: How much human intervention was needed?</li><li><strong>Exploration</strong>: How effectively did the agent explore alternatives?</li><li><strong>Robustness</strong>: How well does the agent handle unexpected situations?</li></ul><h2 id=-applications-of-llm-agents>üöÄ Applications of LLM Agents<a hidden class=anchor aria-hidden=true href=#-applications-of-llm-agents>#</a></h2><p>The potential applications of LLM agents span numerous domains:</p><h3 id=research-assistants>Research Assistants<a hidden class=anchor aria-hidden=true href=#research-assistants>#</a></h3><p>Agents can help researchers by searching literature, summarizing papers, generating hypotheses, and designing experiments.</p><h3 id=personal-assistants>Personal Assistants<a hidden class=anchor aria-hidden=true href=#personal-assistants>#</a></h3><p>Agents can manage calendars, book appointments, organize information, and automate routine tasks based on user preferences.</p><h3 id=software-development>Software Development<a hidden class=anchor aria-hidden=true href=#software-development>#</a></h3><p>Coding agents can write, test, and debug code, as well as implement features based on specifications.</p><h3 id=business-automation>Business Automation<a hidden class=anchor aria-hidden=true href=#business-automation>#</a></h3><p>Agents can process documents, generate reports, analyze data, and automate workflows in business contexts.</p><h3 id=education-and-tutoring>Education and Tutoring<a hidden class=anchor aria-hidden=true href=#education-and-tutoring>#</a></h3><p>Educational agents can provide personalized tutoring, answer questions, and adapt content to a student&rsquo;s learning style.</p><h3 id=customer-support>Customer Support<a hidden class=anchor aria-hidden=true href=#customer-support>#</a></h3><p>These agents can handle customer service tasks, from answering FAQs to resolving complaints and managing customer interactions.</p><h3 id=healthcare>Healthcare<a hidden class=anchor aria-hidden=true href=#healthcare>#</a></h3><p>LLM agents can assist in diagnosing conditions, interpreting medical records, and scheduling appointments.</p><h2 id=-challenges-and-future-directions>üß™ Challenges and Future Directions<a hidden class=anchor aria-hidden=true href=#-challenges-and-future-directions>#</a></h2><p>Despite rapid progress, several challenges remain in developing effective LLM agents:</p><h3 id=1-reliability-and-safety>1. Reliability and Safety<a hidden class=anchor aria-hidden=true href=#1-reliability-and-safety>#</a></h3><p>Agents need guardrails to ensure they don&rsquo;t:</p><ul><li>Take harmful actions</li><li>Execute unintended operations</li><li>Leak sensitive information</li><li>Generate misleading content</li></ul><h3 id=2-scalability>2. Scalability<a hidden class=anchor aria-hidden=true href=#2-scalability>#</a></h3><p>Current approaches often struggle with:</p><ul><li>Very long-term planning</li><li>Complex multi-step tasks</li><li>Large-scale knowledge integration</li><li>Computational efficiency</li></ul><h3 id=3-integration-with-specialized-tools>3. Integration with Specialized Tools<a hidden class=anchor aria-hidden=true href=#3-integration-with-specialized-tools>#</a></h3><p>Building agents that can effectively:</p><ul><li>Interface with domain-specific software</li><li>Control robotic systems</li><li>Work with specialized scientific tools</li><li>Handle multimodal inputs and outputs</li></ul><h3 id=4-ambiguity-in-queries>4. Ambiguity in Queries<a hidden class=anchor aria-hidden=true href=#4-ambiguity-in-queries>#</a></h3><p>LLM agents often face difficulties when handling ambiguous queries. Without additional context, they may generate incorrect or irrelevant responses.</p><h3 id=5-resource-consumption>5. Resource Consumption<a hidden class=anchor aria-hidden=true href=#5-resource-consumption>#</a></h3><p>Running LLM agents, especially those that require continuous interaction with large models and external services, can be resource-intensive.</p><h3 id=6-ethical-concerns>6. Ethical Concerns<a hidden class=anchor aria-hidden=true href=#6-ethical-concerns>#</a></h3><p>There are ethical implications regarding the use of LLM agents in decision-making, privacy concerns, and the potential for misuse. Responsible AI practices and transparency in the model&rsquo;s actions are essential.</p><h2 id=-building-your-own-agent-a-practical-example>üíº Building Your Own Agent: A Practical Example<a hidden class=anchor aria-hidden=true href=#-building-your-own-agent-a-practical-example>#</a></h2><p>Let&rsquo;s build a simple research agent that can search for information and summarize findings:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.agents</span> <span class=kn>import</span> <span class=n>Tool</span><span class=p>,</span> <span class=n>AgentExecutor</span><span class=p>,</span> <span class=n>LLMSingleActionAgent</span><span class=p>,</span> <span class=n>AgentOutputParser</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain.prompts</span> <span class=kn>import</span> <span class=n>StringPromptTemplate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain</span> <span class=kn>import</span> <span class=n>OpenAI</span><span class=p>,</span> <span class=n>SerpAPIWrapper</span><span class=p>,</span> <span class=n>LLMChain</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Union</span><span class=p>,</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Any</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Set up search tool</span>
</span></span><span class=line><span class=cl><span class=n>search</span> <span class=o>=</span> <span class=n>SerpAPIWrapper</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>tools</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=n>Tool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;Search&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>func</span><span class=o>=</span><span class=n>search</span><span class=o>.</span><span class=n>run</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>description</span><span class=o>=</span><span class=s2>&#34;useful for when you need to search for information on the internet&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Set up the prompt template</span>
</span></span><span class=line><span class=cl><span class=n>template</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;You are a research assistant. You have access to the following tools:
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2></span><span class=si>{tools}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>Use the following format:
</span></span></span><span class=line><span class=cl><span class=s2>Question: the input question you must answer
</span></span></span><span class=line><span class=cl><span class=s2>Thought: you should always think about what to do
</span></span></span><span class=line><span class=cl><span class=s2>Action: the action to take, should be one of [</span><span class=si>{tool_names}</span><span class=s2>]
</span></span></span><span class=line><span class=cl><span class=s2>Action Input: the input to the action
</span></span></span><span class=line><span class=cl><span class=s2>Observation: the result of the action
</span></span></span><span class=line><span class=cl><span class=s2>... (this Thought/Action/Action Input/Observation can repeat N times)
</span></span></span><span class=line><span class=cl><span class=s2>Thought: I now know the final answer
</span></span></span><span class=line><span class=cl><span class=s2>Final Answer: the final answer to the original input question
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>Begin!
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>Question: </span><span class=si>{input}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>Thought: &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CustomPromptTemplate</span><span class=p>(</span><span class=n>StringPromptTemplate</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>template</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Tool</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>format</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>intermediate_steps</span> <span class=o>=</span> <span class=n>kwargs</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;intermediate_steps&#34;</span><span class=p>,</span> <span class=p>[])</span>
</span></span><span class=line><span class=cl>        <span class=n>thoughts</span> <span class=o>=</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>action</span><span class=p>,</span> <span class=n>observation</span> <span class=ow>in</span> <span class=n>intermediate_steps</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>thoughts</span> <span class=o>+=</span> <span class=n>action</span><span class=o>.</span><span class=n>log</span>
</span></span><span class=line><span class=cl>            <span class=n>thoughts</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Observation: </span><span class=si>{</span><span class=n>observation</span><span class=si>}</span><span class=se>\n</span><span class=s2>Thought: &#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>kwargs</span><span class=p>[</span><span class=s2>&#34;tools&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>tool</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>tool</span><span class=o>.</span><span class=n>description</span><span class=si>}</span><span class=s2>&#34;</span> <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>tools</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>kwargs</span><span class=p>[</span><span class=s2>&#34;tool_names&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;, &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>([</span><span class=n>tool</span><span class=o>.</span><span class=n>name</span> <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>tools</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>template</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=o>+</span> <span class=n>thoughts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=n>CustomPromptTemplate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>template</span><span class=o>=</span><span class=n>template</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>input_variables</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;input&#34;</span><span class=p>,</span> <span class=s2>&#34;intermediate_steps&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CustomOutputParser</span><span class=p>(</span><span class=n>AgentOutputParser</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>parse</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>llm_output</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Union</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s2>&#34;Final Answer:&#34;</span> <span class=ow>in</span> <span class=n>llm_output</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;output&#34;</span><span class=p>:</span> <span class=n>llm_output</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;Final Answer:&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>regex</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&#34;Action: (.*?)[\n]*Action Input:[\s]*(.*)&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>match</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>regex</span><span class=p>,</span> <span class=n>llm_output</span><span class=p>,</span> <span class=n>re</span><span class=o>.</span><span class=n>DOTALL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=k>match</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;output&#34;</span><span class=p>:</span> <span class=n>llm_output</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>action</span> <span class=o>=</span> <span class=k>match</span><span class=o>.</span><span class=n>group</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>action_input</span> <span class=o>=</span> <span class=k>match</span><span class=o>.</span><span class=n>group</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>(</span><span class=s2>&#34; &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;action&#34;</span><span class=p>:</span> <span class=n>action</span><span class=p>,</span> <span class=s2>&#34;action_input&#34;</span><span class=p>:</span> <span class=n>action_input</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output_parser</span> <span class=o>=</span> <span class=n>CustomOutputParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>llm_chain</span> <span class=o>=</span> <span class=n>LLMChain</span><span class=p>(</span><span class=n>llm</span><span class=o>=</span><span class=n>llm</span><span class=p>,</span> <span class=n>prompt</span><span class=o>=</span><span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>agent</span> <span class=o>=</span> <span class=n>LLMSingleActionAgent</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>llm_chain</span><span class=o>=</span><span class=n>llm_chain</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>output_parser</span><span class=o>=</span><span class=n>output_parser</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>stop</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Observation:&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>allowed_tools</span><span class=o>=</span><span class=p>[</span><span class=n>tool</span><span class=o>.</span><span class=n>name</span> <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=n>tools</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>agent_executor</span> <span class=o>=</span> <span class=n>AgentExecutor</span><span class=o>.</span><span class=n>from_agent_and_tools</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>agent</span><span class=o>=</span><span class=n>agent</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Example usage</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>agent_executor</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=s2>&#34;What are the latest developments in quantum computing?&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=-final-thoughts>üß† Final Thoughts<a hidden class=anchor aria-hidden=true href=#-final-thoughts>#</a></h2><p>LLM agents represent a step change in AI capabilities, moving from models that merely respond to queries to systems that can actively pursue goals. While we&rsquo;re still in the early days of this technology, the rapid progress suggests we&rsquo;re approaching an era of increasingly autonomous and capable AI assistants.</p><p>The most effective agents will likely combine the strengths of LLMs‚Äîreasoning, world knowledge, and flexibility‚Äîwith specialized tools and robust planning frameworks. As these technologies mature, we can expect to see agents that can tackle increasingly complex and open-ended tasks, from scientific research to creative projects and beyond.</p><p>Building effective agents remains a challenging engineering problem, balancing power with reliability, autonomy with control, and capability with safety. The frameworks and approaches outlined in this post provide a starting point, but there&rsquo;s still significant room for innovation in the design and implementation of these systems.</p><p>With advancements in large language models and AI technology, the potential for LLM agents will continue to expand, bringing us closer to fully autonomous, intelligent systems that can understand our needs and act on our behalf with increasing competence and reliability.</p><p>‚Äî <strong>Akshat</strong></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:50281/tags/llm/>LLM</a></li><li><a href=http://localhost:50281/tags/agents/>Agents</a></li><li><a href=http://localhost:50281/tags/deep-learning/>Deep-Learning</a></li><li><a href=http://localhost:50281/tags/ai/>AI</a></li><li><a href=http://localhost:50281/tags/reinforcement-learning/>Reinforcement-Learning</a></li><li><a href=http://localhost:50281/tags/decision-making/>Decision-Making</a></li><li><a href=http://localhost:50281/tags/autonomous-systems/>Autonomous-Systems</a></li></ul><nav class=paginav><a class=prev href=http://localhost:50281/posts/speaker-anonymization/><span class=title>¬´ Prev</span><br><span>Speaker Anonymization: Protecting Voice Identity in the AI Era</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on x" href="https://x.com/intent/tweet/?text=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act&amp;url=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f&amp;hashtags=LLM%2cagents%2cdeep-learning%2cAI%2creinforcement-learning%2cdecision-making%2cautonomous-systems"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f&amp;title=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act&amp;summary=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act&amp;source=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f&title=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on whatsapp" href="https://api.whatsapp.com/send?text=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act%20-%20http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on telegram" href="https://telegram.me/share/url?text=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act&amp;url=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share LLM Agents: Building AI Systems That Can Reason and Act on ycombinator" href="https://news.ycombinator.com/submitlink?t=LLM%20Agents%3a%20Building%20AI%20Systems%20That%20Can%20Reason%20and%20Act&u=http%3a%2f%2flocalhost%3a50281%2fposts%2fllm-agents%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:50281/>Akshat Gupta</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>