<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generative-Ai on Akshat Gupta</title>
    <link>https://akshat4112.github.io/tags/generative-ai/</link>
    <description>Recent content in Generative-Ai on Akshat Gupta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 15 Jul 2024 09:00:00 +0100</lastBuildDate>
    <atom:link href="https://akshat4112.github.io/tags/generative-ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What are Diffusion Models?</title>
      <link>https://akshat4112.github.io/posts/what_are_diffusion_models/</link>
      <pubDate>Thu, 15 Feb 2024 09:00:00 +0100</pubDate>
      <guid>https://akshat4112.github.io/posts/what_are_diffusion_models/</guid>
      <description>Generative modeling is currently one of the most thrilling domains in deep learning research. Traditional models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) have already demonstrated impressive capabilities in synthetically generating realistic data, such as images and text. However, diffusion models is swiftly gaining prominence as a powerful model in the arena of high-quality and stable generative modeling. This blog explores diffusion models, examining their operational mechanisms, architectural designs, training processes, sampling methods, and the key advantages that position them at the forefront of generative AI.</description>
    </item>
    <item>
      <title>RAG and LLMs: Teaching Large Models to Use External Knowledge</title>
      <link>https://akshat4112.github.io/posts/rag-and-llms/</link>
      <pubDate>Mon, 15 Jul 2024 09:00:00 +0100</pubDate>
      <guid>https://akshat4112.github.io/posts/rag-and-llms/</guid>
      <description>Large Language Models (LLMs) like GPT or LLaMA are great at generating text. But there&amp;rsquo;s a catch:
They only know what they were trained on, and that knowledge is frozen at training time.
So what happens when you ask them something from after their training cutoff? Or something super niche, like a policy from your internal HR docs?
Enter RAG â€“ Retrieval-Augmented Generation.
A technique that combines LLMs with a search engine, enabling them to look up facts on the fly.</description>
    </item>
  </channel>
</rss>
