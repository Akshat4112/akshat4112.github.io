<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Akshat Gupta</title>
    <link>http://localhost:50281/tags/ai/</link>
    <description>Recent content in AI on Akshat Gupta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 05 May 2025 09:00:00 +0100</lastBuildDate>
    <atom:link href="http://localhost:50281/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fairness in Machine Learning</title>
      <link>http://localhost:50281/posts/fairness_in_machine_learning_/</link>
      <pubDate>Sun, 15 Oct 2023 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/fairness_in_machine_learning_/</guid>
      <description>As machine learning systems are increasingly used in critical areas like finance, employment, and criminal justice, it&amp;rsquo;s essential to ensure these models are fair and do not discriminate against certain groups. In this post, I will explore the concept of fairness in machine learning.
Defining Fairness Fairness in machine learning can be understood in several ways:
Group Fairness: This implies equal treatment or outcomes for different groups categorized by sensitive attributes like race or gender.</description>
    </item>
    <item>
      <title>What is an Ontology in a Knowledge Graph?</title>
      <link>http://localhost:50281/posts/ontology-in-knowledge-graphs/</link>
      <pubDate>Mon, 15 Jan 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/ontology-in-knowledge-graphs/</guid>
      <description>If you&amp;rsquo;re working with knowledge graphs, one term that keeps popping up is ontology. Sounds academic, right? Like something you&amp;rsquo;d find buried in a philosophy textbook.
But in the world of AI, data science, and search engines, an ontology is far from abstract â€” it&amp;rsquo;s the blueprint that gives your knowledge graph meaning. Let&amp;rsquo;s break it down and explore how it all fits together.
ðŸ§  What Is an Ontology (in AI)?</description>
    </item>
    <item>
      <title>LLM Fine-Tuning and LoRA: Making Large Models Work for You</title>
      <link>http://localhost:50281/posts/llm-fine-tuning-lora/</link>
      <pubDate>Sun, 20 Apr 2025 17:30:00 +0200</pubDate>
      <guid>http://localhost:50281/posts/llm-fine-tuning-lora/</guid>
      <description>As powerful as large language models (LLMs) like GPT, LLaMA, and Mistral are, theyâ€™re still general-purpose. If you want to make them truly useful for your domainâ€”whether itâ€™s legal documents, financial analysis, or German tax lawâ€”you need to fine-tune them.
And thanks to a technique called LoRA (Low-Rank Adaptation), you can now fine-tune LLMs with a fraction of the data, compute, and cost.
ðŸ”§ What is Fine-Tuning? Fine-tuning is the process of continuing the training of a pre-trained LLM on your own dataset so that it learns domain-specific patterns, vocabulary, tone, or tasks.</description>
    </item>
    <item>
      <title>What Are Knowledge Graphs?</title>
      <link>http://localhost:50281/posts/what-are-knowledge-graphs/</link>
      <pubDate>Fri, 15 Mar 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/what-are-knowledge-graphs/</guid>
      <description>We hear the term knowledge graph everywhere now â€” from Google Search to enterprise AI to GenAI apps. But what exactly is a knowledge graph, and why is everyone suddenly obsessed with it?
In this post, I&amp;rsquo;ll break down knowledge graphs in plain language: what they are, how they work, and how I use them in my own projects.
ðŸ§± The Basics: What Is a Knowledge Graph? At its core, a knowledge graph is a network of real-world entities (people, places, things) and the relationships between them.</description>
    </item>
    <item>
      <title>Prompt Engineering: The Art of Talking to AI</title>
      <link>http://localhost:50281/posts/prompt-engineering/</link>
      <pubDate>Mon, 15 Apr 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/prompt-engineering/</guid>
      <description>We&amp;rsquo;ve all played with ChatGPT, Copilot, or Claude â€” typing in questions and marveling at their responses. But behind the scenes, there&amp;rsquo;s a powerful craft at play: prompt engineering.
It&amp;rsquo;s not just about &amp;ldquo;asking a question.&amp;rdquo; It&amp;rsquo;s about how you phrase it, structure it, and guide the model. Prompt engineering is the new programming skill â€” and it&amp;rsquo;s transforming how we interact with AI.
ðŸ§  What Is Prompt Engineering? Prompt engineering is the process of designing effective input prompts that guide large language models (LLMs) like GPT-4 to produce accurate, helpful, or creative outputs.</description>
    </item>
    <item>
      <title>Evaluating LLMs: How Do You Measure a Model&#39;s Mind?</title>
      <link>http://localhost:50281/posts/evaluating-llms/</link>
      <pubDate>Sat, 15 Jun 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/evaluating-llms/</guid>
      <description>As large language models (LLMs) become central to search, productivity tools, education, and coding, evaluating them is no longer optional. You have to ask:
Is this model reliable? Accurate? Safe? Biased? Smart enough for my task?
But here&amp;rsquo;s the catch: LLMs are not deterministic functions. They generate free-form text, can be right in one sentence and wrong in the next â€” and vary wildly depending on the prompt.
So how do we evaluate them meaningfully?</description>
    </item>
    <item>
      <title>RAG and LLMs: Teaching Large Models to Use External Knowledge</title>
      <link>http://localhost:50281/posts/rag-and-llms/</link>
      <pubDate>Mon, 15 Jul 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/rag-and-llms/</guid>
      <description>Large Language Models (LLMs) like GPT or LLaMA are great at generating text. But there&amp;rsquo;s a catch:
They only know what they were trained on, and that knowledge is frozen at training time.
So what happens when you ask them something from after their training cutoff? Or something super niche, like a policy from your internal HR docs?
Enter RAG â€“ Retrieval-Augmented Generation.
A technique that combines LLMs with a search engine, enabling them to look up facts on the fly.</description>
    </item>
    <item>
      <title>Understanding Attention in Transformers: The Core of Modern NLP</title>
      <link>http://localhost:50281/posts/attention-in-transformers/</link>
      <pubDate>Thu, 15 Aug 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/attention-in-transformers/</guid>
      <description>When people say &amp;ldquo;Transformers revolutionized NLP,&amp;rdquo; what they really mean is:
Attention revolutionized NLP.
From GPT and BERT to LLaMA and Claude, attention mechanisms are the beating heart of modern large language models.
But what exactly is attention? Why is it so powerful? And how many types are there?
Let&amp;rsquo;s dive in.
ðŸ§  What is Attention? In the simplest sense, attention is a way for a model to focus on the most relevant parts of the input when generating output.</description>
    </item>
    <item>
      <title>Model Extraction Attacks: How Hackers Steal AI Models</title>
      <link>http://localhost:50281/posts/model-extraction-attacks/</link>
      <pubDate>Sun, 15 Sep 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/model-extraction-attacks/</guid>
      <description>In the world of machine learning, especially with the rise of large language models (LLMs) and deep neural networks, model extraction attacks are a growing concern. These attacks aim to replicate the behavior of a machine learning model by querying it and then using the responses to reverse-engineer its underlying architecture and parameters.
What is a Model Extraction Attack? A model extraction attack occurs when an adversary tries to replicate a machine learning model by making repeated queries to it and analyzing its responses.</description>
    </item>
    <item>
      <title>Speaker Anonymization: Protecting Voice Identity in the AI Era</title>
      <link>http://localhost:50281/posts/speaker-anonymization/</link>
      <pubDate>Tue, 15 Oct 2024 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/speaker-anonymization/</guid>
      <description>Speaker anonymization refers to the process of modifying the characteristics of a speaker&amp;rsquo;s voice so that the speaker&amp;rsquo;s identity cannot be easily determined while preserving the speech&amp;rsquo;s intelligibility. With the increasing usage of speech data in virtual assistants, surveillance systems, and other applications, ensuring privacy in speech data has become critical.
In this post, we&amp;rsquo;ll dive into the technical details of speaker anonymization techniques, including implementation approaches using machine learning, deep learning models, and popular libraries.</description>
    </item>
    <item>
      <title>LLM Agents: Building AI Systems That Can Reason and Act</title>
      <link>http://localhost:50281/posts/llm-agents/</link>
      <pubDate>Mon, 05 May 2025 09:00:00 +0100</pubDate>
      <guid>http://localhost:50281/posts/llm-agents/</guid>
      <description>Understanding LLM Agents: The Future of Autonomous AI Systems Large Language Models (LLMs), like GPT-3, GPT-4, and others, have taken the world by storm due to their impressive language generation and understanding capabilities. However, when these models are augmented with decision-making capabilities, memory, and actions in specific environments, they become even more powerful. Enter LLM Agents â€” autonomous systems built on top of large language models to perform tasks, make decisions, and act autonomously based on user instructions.</description>
    </item>
  </channel>
</rss>
